{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n7SuYMTZClZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "mv9WYcrozC_L",
    "outputId": "a5a9a314-47df-4f6c-985b-140e1f131229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDdEZ3K3Zcv5"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/My Drive/Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0MpOR7t5uh7"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath('/content/drive/My Drive/EmbeddingDownloaded/glove.6B.50d.txt')\n",
    "tmp_file = get_tmpfile(\"/content/drive/My Drive/EmbeddingDownloaded/word2vec.6B.50d.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bOF7UDCcvJ9"
   },
   "outputs": [],
   "source": [
    "file=open('/content/drive/My Drive/Deep Learning/conversation.json')\n",
    "data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_mehlnzdKWE"
   },
   "outputs": [],
   "source": [
    "x = list()\n",
    "y = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-1j5XO_dn5E"
   },
   "outputs": [],
   "source": [
    "conversations = data['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqxyICVHeJes"
   },
   "outputs": [],
   "source": [
    "for conversation in conversations:\n",
    "  for position in range(len(conversation)):\n",
    "    if position < (len(conversation)-1):\n",
    "      x.append(conversation[position])\n",
    "      y.append(conversation[position+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPf1oRhxiMBD"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(x, y)), columns = ['Question' , 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udNsgmZH2YlA"
   },
   "outputs": [],
   "source": [
    "df['Answer'] = \"startseq \" + df['Answer'] + \" endseq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGis6BZjjEu-"
   },
   "outputs": [],
   "source": [
    "#Cleaning the Train Dataset\n",
    "df['Question'] = df['Question'].apply(lambda x: x.lower())\n",
    "df['Answer'] = df['Answer'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWMQZzNqUhJ"
   },
   "outputs": [],
   "source": [
    "df['Question']  = df['Question'].str.replace(\"won't\",\"will not\")\n",
    "df['Question']  = df['Question'].str.replace(\"ain't\",\"am not\")\n",
    "df['Question']  = df['Question'].str.replace(\"'s\",\" is\")\n",
    "df['Question']  = df['Question'].str.replace(\"'m\",\" am\")\n",
    "df['Question']  = df['Question'].str.replace(\"'re'\",\" are\")\n",
    "df['Question']  = df['Question'].str.replace(\"can't\",\"can not\")\n",
    "df['Question']  = df['Question'].str.replace(\"'ll\",\" will\")\n",
    "df['Question']  = df['Question'].str.replace(\"n't\",\" not\")\n",
    "\n",
    "df['Answer']  = df['Answer'].str.replace(\"won't\",\"will not\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"ain't\",\"am not\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'s\",\" is\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'m\",\" am\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'re'\",\" are\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"can't\",\"can not\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'ll\",\" will\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"n't\",\" not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdE3vGGwUeXW"
   },
   "outputs": [],
   "source": [
    "df['Question'] = df['Question'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x)) #removing all charecters except alphabets\n",
    "df['Question'] = df['Question'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces\n",
    "df['Answer'] = df['Answer'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x)) #removing all charecters except alphabets\n",
    "df['Answer'] = df['Answer'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_ndHMaIqbPG"
   },
   "outputs": [],
   "source": [
    "df['Question'] = df['Question'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df['Answer'] = df['Answer'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwWR5PXvd3Ey"
   },
   "outputs": [],
   "source": [
    "encoder_input = []\n",
    "decoder_input = []\n",
    "decoder_output = []\n",
    "for i in range(len(df['Question'])):\n",
    "  temp_list = []\n",
    "  for j in range(len(df['Answer'][i])):\n",
    "    if j < (len(df['Answer'][i])-1):\n",
    "      temp_list.append(df['Answer'][i][j])\n",
    "      encoder_input.append(df['Answer'][i])\n",
    "      decoder_input.append((temp_list).copy())\n",
    "      decoder_output.append(df['Answer'][i][j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xcqr41Tc0Z_P"
   },
   "outputs": [],
   "source": [
    "#Encoder Sequence Length Maximum\n",
    "encoder_sequence_length = max([len(x) for x in encoder_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bqQRuGD6aXz"
   },
   "outputs": [],
   "source": [
    "#Decoder Sequence Length Maximum\n",
    "decoder_sequence_length = max([len(x) for x in decoder_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0j2urzTS5hK"
   },
   "outputs": [],
   "source": [
    "def word_padding_post(words_list):\n",
    "  temp_list = (words_list + ((decoder_sequence_length-len(words_list))  * ['zerovector']))\n",
    "  return temp_list\n",
    "\n",
    "def word_padding_pre(words_list):\n",
    "  temp_list = (((encoder_sequence_length-len(words_list))  * ['zerovector'])+ words_list)\n",
    "  return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmPGjD_CNuLi"
   },
   "outputs": [],
   "source": [
    "def vector_conversion(word_list):\n",
    "  return_list = []\n",
    "  for word in word_list:\n",
    "    if word in model.wv.vocab:\n",
    "      return_list.append(model[word])\n",
    "    else:\n",
    "      return_list.append(np.zeros(50,dtype='float32'))\n",
    "  return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "UVfbVNQEinjC",
    "outputId": "fdc12900-02ec-4235-c20f-b0da9a9e9cc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for Listno in range(len(encoder_input)):\n",
    "  encoder_input[Listno] = word_padding_pre(encoder_input[Listno])\n",
    "  encoder_input[Listno] = vector_conversion(encoder_input[Listno])\n",
    "  decoder_input[Listno] = word_padding_pre(decoder_input[Listno])\n",
    "  decoder_input[Listno] = vector_conversion(decoder_input[Listno])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "nS-EmRISjbBT",
    "outputId": "9300a6a0-1ad4-4fb8-b3e9-56b1d6d26d59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for index in range(len(decoder_output)):\n",
    "  if decoder_output[index] in model.wv.vocab:\n",
    "    decoder_output[index] = model[decoder_output[index]]\n",
    "  else:\n",
    "    decoder_output[index] = np.zeros(50,dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s7kJFmCH7m9X",
    "outputId": "3dafbed4-c8c7-42df-89b4-da0156439928"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kissane'"
      ]
     },
     "execution_count": 201,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(np.array(encoder_input[0][0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXMiUv85HpNi"
   },
   "outputs": [],
   "source": [
    "#Model Creation - Functional Type - Encoder\n",
    "# Define an input sequence and process it.\n",
    "encoder_Inputs = tf.keras.layers.Input(shape=(encoder_sequence_length,50))\n",
    "encoder = tf.keras.layers.LSTM(256,return_state=True)\n",
    "encoder_outputs, hidden_state, cell_state = encoder(encoder_Inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [hidden_state, cell_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ntAYiISYsow"
   },
   "outputs": [],
   "source": [
    "#Model Creation - Functional Type - Decoder\n",
    "decoder_Inputs = tf.keras.layers.Input(shape=(encoder_sequence_length,50))\n",
    "decoder = tf.keras.layers.LSTM(256)\n",
    "decoder_outputs = decoder(decoder_Inputs,initial_state = encoder_states)\n",
    "decoder_final_output = tf.keras.layers.Dense(50, activation= 'softmax')(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZwkzcz1c8w0"
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "chatmodel = tf.keras.Model([encoder_Inputs, decoder_Inputs], decoder_final_output)\n",
    "chatmodel.compile(loss='cosine_proximity', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "87k3vNsbde_y",
    "outputId": "68d81d83-4cbe-4b69-addf-6d871144e6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 30, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 30, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 256), (None, 314368      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 256)          314368      input_6[0][0]                    \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           12850       lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 641,586\n",
      "Trainable params: 641,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chatmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "wXPG-eoGd2PU",
    "outputId": "88a1c4be-b886-4249-8921-744b2514ed1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 487 samples, validate on 122 samples\n",
      "Epoch 1/3\n",
      "487/487 [==============================] - 13s 27ms/sample - loss: -0.5674 - acc: 0.7823 - val_loss: -0.5574 - val_acc: 0.8033\n",
      "Epoch 2/3\n",
      "487/487 [==============================] - 13s 27ms/sample - loss: -0.5716 - acc: 0.7823 - val_loss: -0.5570 - val_acc: 0.8033\n",
      "Epoch 3/3\n",
      "487/487 [==============================] - 13s 27ms/sample - loss: -0.5738 - acc: 0.7823 - val_loss: -0.5565 - val_acc: 0.8033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2dc49d1d30>"
      ]
     },
     "execution_count": 207,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel.fit([encoder_input, decoder_input], np.array(decoder_output), batch_size=4, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "oFv50MplqsTM",
    "outputId": "42cd7f0b-a8f8-4dad-f831-1eb6cf2758b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('so', 0.8277916312217712),\n",
       " ('there', 0.819884181022644),\n",
       " ('can', 0.8198361396789551),\n",
       " ('very', 0.8169803023338318),\n",
       " ('be', 0.8159558176994324),\n",
       " ('rest', 0.8152173757553101),\n",
       " ('this', 0.8104703426361084),\n",
       " ('longer', 0.8100574612617493),\n",
       " ('all', 0.8090950846672058),\n",
       " ('it', 0.8074486255645752)]"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(chatmodel.predict([encoder_input[0:1], decoder_input[0:1]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "MEG2zgLrsEd1",
    "outputId": "2d5a2e80-ec52-4d1a-ce4c-c010180fa56e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.18345667e-02, 1.39106335e-02, 1.36144314e-04, 1.72421991e-04,\n",
       "        4.51465212e-02, 1.34517206e-02, 1.20810531e-04, 2.32319406e-04,\n",
       "        1.23055637e-04, 1.63330473e-02, 2.80022301e-04, 4.21347171e-02,\n",
       "        8.72102173e-05, 1.96870416e-04, 7.09684044e-02, 5.51160127e-02,\n",
       "        3.05291936e-02, 1.23664979e-02, 2.97881837e-04, 6.80227167e-05,\n",
       "        1.04624174e-04, 3.15407664e-02, 4.59026359e-02, 2.96458844e-02,\n",
       "        5.37480079e-02, 5.32307786e-05, 6.37435369e-05, 2.10295245e-02,\n",
       "        4.94366698e-02, 6.31455696e-05, 2.60017604e-01, 3.04463413e-02,\n",
       "        1.08919252e-04, 8.02399809e-05, 2.99018662e-04, 2.13188861e-04,\n",
       "        1.14575233e-02, 1.38959354e-02, 6.89863972e-03, 9.09245864e-05,\n",
       "        1.92344945e-04, 7.75981368e-03, 7.21316028e-04, 4.12519015e-02,\n",
       "        4.47543745e-04, 9.81524680e-03, 3.89741181e-04, 1.28284341e-03,\n",
       "        4.77313471e-04, 3.90593037e-02]], dtype=float32)"
      ]
     },
     "execution_count": 213,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel.predict([encoder_input[0:1], decoder_input[1:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "MaWh8nmEsY9v",
    "outputId": "e2d714da-7cfe-4a27-930d-114960123610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('am', 0.9999999403953552),\n",
       " (\"'m\", 0.7501711845397949),\n",
       " ('i', 0.7385112047195435),\n",
       " ('sorry', 0.7095773816108704),\n",
       " ('me', 0.7072381973266602),\n",
       " ('nobody', 0.7045166492462158),\n",
       " ('yes', 0.7002850770950317),\n",
       " ('tomorrow', 0.6995285153388977),\n",
       " ('happened', 0.6980783939361572),\n",
       " ('everybody', 0.694588303565979)]"
      ]
     },
     "execution_count": 214,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(decoder_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1088
    },
    "colab_type": "code",
    "id": "wKnt4zaftCLW",
    "outputId": "3682d982-9b45-44c5-eb38-0447e9674bbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [i, am, doing, well, how, about, you]\n",
       "1                                   [i, am, also, good]\n",
       "2                            [that, is, good, to, hear]\n",
       "3                                         [yes, it, is]\n",
       "4                                                  [hi]\n",
       "5                                [how, are, you, doing]\n",
       "6                                  [i, am, doing, well]\n",
       "7                            [that, is, good, to, hear]\n",
       "8                                         [yes, it, is]\n",
       "9                   [can, i, help, you, with, anything]\n",
       "10                          [yes, i, have, a, question]\n",
       "11                           [what, is, your, question]\n",
       "12                [could, i, borrow, a, cup, of, sugar]\n",
       "13           [i, am, sorry, but, i, do, not, have, any]\n",
       "14                                 [thank, you, anyway]\n",
       "15                                        [no, problem]\n",
       "16                [i, am, doing, well, how, about, you]\n",
       "17                                  [i, am, also, good]\n",
       "18                                     [that, is, good]\n",
       "19                                   [what, good, news]\n",
       "20                                  [i, can, not, read]\n",
       "21                [so, what, is, your, favorite, color]\n",
       "22                                               [blue]\n",
       "23    [who, who, is, but, a, form, following, the, f...\n",
       "24                               [what, are, you, then]\n",
       "25                                [a, man, in, a, mask]\n",
       "26                                  [i, can, see, that]\n",
       "27    [it, is, not, your, powers, of, observation, i...\n",
       "28                            [i, like, seeing, movies]\n",
       "29              [what, kind, of, movies, do, you, like]\n",
       "                            ...                        \n",
       "56             [complex, is, better, than, complicated]\n",
       "57                     [flat, is, better, than, nested]\n",
       "58                    [sparse, is, better, than, dense]\n",
       "59                                [readability, counts]\n",
       "60    [special, cases, are, not, special, enough, to...\n",
       "61              [although, practicality, beats, purity]\n",
       "62              [errors, should, never, pass, silently]\n",
       "63                       [unless, explicitly, silenced]\n",
       "64    [in, the, face, of, ambiguity, refuse, the, te...\n",
       "65    [there, should, be, one, and, preferably, only...\n",
       "66    [although, that, way, may, not, be, obvious, a...\n",
       "67                       [now, is, better, than, never]\n",
       "68    [although, never, is, often, better, than, rig...\n",
       "69    [if, the, implementation, is, hard, to, explai...\n",
       "70    [if, the, implementation, is, easy, to, explai...\n",
       "71    [namespaces, are, one, honking, great, idea, l...\n",
       "72                                           [i, agree]\n",
       "73                               [i, am, a, programmer]\n",
       "74            [what, languages, do, you, like, to, use]\n",
       "75         [i, use, python, java, and, c, quite, often]\n",
       "76              [i, use, python, quite, a, bit, myself]\n",
       "77             [i, am, not, incredibly, fond, of, java]\n",
       "78                                  [what, annoys, you]\n",
       "79                     [it, has, many, inconsistencies]\n",
       "80    [it, means, you, only, live, once, where, did,...\n",
       "81                        [i, heard, somebody, say, it]\n",
       "82                [it, depends, how, you, define, life]\n",
       "83    [life, is, the, condition, that, distinguishes...\n",
       "84           [is, that, a, definition, or, an, opinion]\n",
       "85                                [go, ahead, and, ask]\n",
       "Name: Answer, Length: 86, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5VF6Ynv7to4z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ChatBot_encoder_decoder_sequence_dense.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
