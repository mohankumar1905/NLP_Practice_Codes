{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot_encoder_decoder_sequence_dense.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4mFSCqqZJX5",
        "colab_type": "code",
        "outputId": "bc3aa7d7-8b3b-46a8-b430-fc10f85f9c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csCLTAJ_EZ-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(\"/content/drive/My Drive/1_tpot_iris_pipeline.py\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umZ-g8yTE5Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_contents = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaSyXe7IFoCK",
        "colab_type": "code",
        "outputId": "3960da1b-147a-4ba5-9e3f-665dc3fcc5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "file_contents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.pipeline import make_pipeline, make_union\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom tpot.builtins import StackingEstimator\\n\\n# NOTE: Make sure that the class is labeled \\'target\\' in the data file\\ntpot_data = pd.read_csv(\\'PATH/TO/DATA/FILE\\', sep=\\'COLUMN_SEPARATOR\\', dtype=np.float64)\\nfeatures = tpot_data.drop(\\'target\\', axis=1).values\\ntraining_features, testing_features, training_target, testing_target = \\\\\\n            train_test_split(features, tpot_data[\\'target\\'].values, random_state=23)\\n\\n# Average CV score on the training set was:0.9839803080877585\\nexported_pipeline = make_pipeline(\\n    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=4, min_samples_leaf=7, min_samples_split=15)),\\n    KNeighborsClassifier(n_neighbors=13, p=2, weights=\"uniform\")\\n)\\n\\nexported_pipeline.fit(training_features, training_target)\\nresults = exported_pipeline.predict(testing_features)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n7SuYMTZClZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim import corpora, models, similarities\n",
        "import pickle\n",
        "import csv\n",
        "import re\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv9WYcrozC_L",
        "colab_type": "code",
        "outputId": "a5a9a314-47df-4f6c-985b-140e1f131229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDdEZ3K3Zcv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Deep Learning\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0MpOR7t5uh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/content/drive/My Drive/EmbeddingDownloaded/glove.6B.50d.txt')\n",
        "tmp_file = get_tmpfile(\"/content/drive/My Drive/EmbeddingDownloaded/word2vec.6B.50d.txt\")\n",
        "_ = glove2word2vec(glove_file, tmp_file)\n",
        "model = KeyedVectors.load_word2vec_format(tmp_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bOF7UDCcvJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=open('/content/drive/My Drive/Deep Learning/conversation.json')\n",
        "data = json.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_mehlnzdKWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = list()\n",
        "y = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-1j5XO_dn5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conversations = data['conversations']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqxyICVHeJes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for conversation in conversations:\n",
        "  for position in range(len(conversation)):\n",
        "    if position < (len(conversation)-1):\n",
        "      x.append(conversation[position])\n",
        "      y.append(conversation[position+1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPf1oRhxiMBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(list(zip(x, y)), columns = ['Question' , 'Answer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udNsgmZH2YlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Answer'] = \"startseq \" + df['Answer'] + \" endseq\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGis6BZjjEu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning the Train Dataset\n",
        "df['Question'] = df['Question'].apply(lambda x: x.lower())\n",
        "df['Answer'] = df['Answer'].apply(lambda x: x.lower())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTWMQZzNqUhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Question']  = df['Question'].str.replace(\"won't\",\"will not\")\n",
        "df['Question']  = df['Question'].str.replace(\"ain't\",\"am not\")\n",
        "df['Question']  = df['Question'].str.replace(\"'s\",\" is\")\n",
        "df['Question']  = df['Question'].str.replace(\"'m\",\" am\")\n",
        "df['Question']  = df['Question'].str.replace(\"'re'\",\" are\")\n",
        "df['Question']  = df['Question'].str.replace(\"can't\",\"can not\")\n",
        "df['Question']  = df['Question'].str.replace(\"'ll\",\" will\")\n",
        "df['Question']  = df['Question'].str.replace(\"n't\",\" not\")\n",
        "\n",
        "df['Answer']  = df['Answer'].str.replace(\"won't\",\"will not\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"ain't\",\"am not\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"'s\",\" is\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"'m\",\" am\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"'re'\",\" are\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"can't\",\"can not\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"'ll\",\" will\")\n",
        "df['Answer']  = df['Answer'].str.replace(\"n't\",\" not\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdE3vGGwUeXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Question'] = df['Question'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x)) #removing all charecters except alphabets\n",
        "df['Question'] = df['Question'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces\n",
        "df['Answer'] = df['Answer'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x)) #removing all charecters except alphabets\n",
        "df['Answer'] = df['Answer'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ndHMaIqbPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Question'] = df['Question'].apply(lambda x: nltk.word_tokenize(x))\n",
        "df['Answer'] = df['Answer'].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwWR5PXvd3Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = []\n",
        "decoder_input = []\n",
        "decoder_output = []\n",
        "for i in range(len(df['Question'])):\n",
        "  temp_list = []\n",
        "  for j in range(len(df['Answer'][i])):\n",
        "    if j < (len(df['Answer'][i])-1):\n",
        "      temp_list.append(df['Answer'][i][j])\n",
        "      encoder_input.append(df['Answer'][i])\n",
        "      decoder_input.append((temp_list).copy())\n",
        "      decoder_output.append(df['Answer'][i][j+1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcqr41Tc0Z_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoder Sequence Length Maximum\n",
        "encoder_sequence_length = max([len(x) for x in encoder_input])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bqQRuGD6aXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decoder Sequence Length Maximum\n",
        "decoder_sequence_length = max([len(x) for x in decoder_input])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0j2urzTS5hK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_padding_post(words_list):\n",
        "  temp_list = (words_list + ((decoder_sequence_length-len(words_list))  * ['zerovector']))\n",
        "  return temp_list\n",
        "\n",
        "def word_padding_pre(words_list):\n",
        "  temp_list = (((encoder_sequence_length-len(words_list))  * ['zerovector'])+ words_list)\n",
        "  return temp_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmPGjD_CNuLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vector_conversion(word_list):\n",
        "  return_list = []\n",
        "  for word in word_list:\n",
        "    if word in model.wv.vocab:\n",
        "      return_list.append(model[word])\n",
        "    else:\n",
        "      return_list.append(np.zeros(50,dtype='float32'))\n",
        "  return return_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVfbVNQEinjC",
        "colab_type": "code",
        "outputId": "fdc12900-02ec-4235-c20f-b0da9a9e9cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for Listno in range(len(encoder_input)):\n",
        "  encoder_input[Listno] = word_padding_pre(encoder_input[Listno])\n",
        "  encoder_input[Listno] = vector_conversion(encoder_input[Listno])\n",
        "  decoder_input[Listno] = word_padding_pre(decoder_input[Listno])\n",
        "  decoder_input[Listno] = vector_conversion(decoder_input[Listno])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS-EmRISjbBT",
        "colab_type": "code",
        "outputId": "9300a6a0-1ad4-4fb8-b3e9-56b1d6d26d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for index in range(len(decoder_output)):\n",
        "  if decoder_output[index] in model.wv.vocab:\n",
        "    decoder_output[index] = model[decoder_output[index]]\n",
        "  else:\n",
        "    decoder_output[index] = np.zeros(50,dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7kJFmCH7m9X",
        "colab_type": "code",
        "outputId": "3dafbed4-c8c7-42df-89b4-da0156439928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.similar_by_vector(np.array(encoder_input[0][0]))[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kissane'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXMiUv85HpNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Creation - Functional Type - Encoder\n",
        "# Define an input sequence and process it.\n",
        "encoder_Inputs = tf.keras.layers.Input(shape=(encoder_sequence_length,50))\n",
        "encoder = tf.keras.layers.LSTM(256,return_state=True)\n",
        "encoder_outputs, hidden_state, cell_state = encoder(encoder_Inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [hidden_state, cell_state]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ntAYiISYsow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Creation - Functional Type - Decoder\n",
        "decoder_Inputs = tf.keras.layers.Input(shape=(encoder_sequence_length,50))\n",
        "decoder = tf.keras.layers.LSTM(256)\n",
        "decoder_outputs = decoder(decoder_Inputs,initial_state = encoder_states)\n",
        "decoder_final_output = tf.keras.layers.Dense(50, activation= 'softmax')(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZwkzcz1c8w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "chatmodel = tf.keras.Model([encoder_Inputs, decoder_Inputs], decoder_final_output)\n",
        "chatmodel.compile(loss='cosine_proximity', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87k3vNsbde_y",
        "colab_type": "code",
        "outputId": "68d81d83-4cbe-4b69-addf-6d871144e6f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "chatmodel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 30, 50)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 30, 50)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 256), (None, 314368      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 256)          314368      input_6[0][0]                    \n",
            "                                                                 lstm_4[0][1]                     \n",
            "                                                                 lstm_4[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 50)           12850       lstm_5[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 641,586\n",
            "Trainable params: 641,586\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXPG-eoGd2PU",
        "colab_type": "code",
        "outputId": "88a1c4be-b886-4249-8921-744b2514ed1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "chatmodel.fit([encoder_input, decoder_input], np.array(decoder_output), batch_size=4, epochs=3, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 487 samples, validate on 122 samples\n",
            "Epoch 1/3\n",
            "487/487 [==============================] - 13s 27ms/sample - loss: -0.5674 - acc: 0.7823 - val_loss: -0.5574 - val_acc: 0.8033\n",
            "Epoch 2/3\n",
            "487/487 [==============================] - 13s 27ms/sample - loss: -0.5716 - acc: 0.7823 - val_loss: -0.5570 - val_acc: 0.8033\n",
            "Epoch 3/3\n",
            "487/487 [==============================] - 13s 27ms/sample - loss: -0.5738 - acc: 0.7823 - val_loss: -0.5565 - val_acc: 0.8033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dc49d1d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFv50MplqsTM",
        "colab_type": "code",
        "outputId": "42cd7f0b-a8f8-4dad-f831-1eb6cf2758b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "model.similar_by_vector(chatmodel.predict([encoder_input[0:1], decoder_input[0:1]])[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('so', 0.8277916312217712),\n",
              " ('there', 0.819884181022644),\n",
              " ('can', 0.8198361396789551),\n",
              " ('very', 0.8169803023338318),\n",
              " ('be', 0.8159558176994324),\n",
              " ('rest', 0.8152173757553101),\n",
              " ('this', 0.8104703426361084),\n",
              " ('longer', 0.8100574612617493),\n",
              " ('all', 0.8090950846672058),\n",
              " ('it', 0.8074486255645752)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEG2zgLrsEd1",
        "colab_type": "code",
        "outputId": "2d5a2e80-ec52-4d1a-ce4c-c010180fa56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "chatmodel.predict([encoder_input[0:1], decoder_input[1:2]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.18345667e-02, 1.39106335e-02, 1.36144314e-04, 1.72421991e-04,\n",
              "        4.51465212e-02, 1.34517206e-02, 1.20810531e-04, 2.32319406e-04,\n",
              "        1.23055637e-04, 1.63330473e-02, 2.80022301e-04, 4.21347171e-02,\n",
              "        8.72102173e-05, 1.96870416e-04, 7.09684044e-02, 5.51160127e-02,\n",
              "        3.05291936e-02, 1.23664979e-02, 2.97881837e-04, 6.80227167e-05,\n",
              "        1.04624174e-04, 3.15407664e-02, 4.59026359e-02, 2.96458844e-02,\n",
              "        5.37480079e-02, 5.32307786e-05, 6.37435369e-05, 2.10295245e-02,\n",
              "        4.94366698e-02, 6.31455696e-05, 2.60017604e-01, 3.04463413e-02,\n",
              "        1.08919252e-04, 8.02399809e-05, 2.99018662e-04, 2.13188861e-04,\n",
              "        1.14575233e-02, 1.38959354e-02, 6.89863972e-03, 9.09245864e-05,\n",
              "        1.92344945e-04, 7.75981368e-03, 7.21316028e-04, 4.12519015e-02,\n",
              "        4.47543745e-04, 9.81524680e-03, 3.89741181e-04, 1.28284341e-03,\n",
              "        4.77313471e-04, 3.90593037e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaWh8nmEsY9v",
        "colab_type": "code",
        "outputId": "e2d714da-7cfe-4a27-930d-114960123610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "model.similar_by_vector(decoder_output[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('am', 0.9999999403953552),\n",
              " (\"'m\", 0.7501711845397949),\n",
              " ('i', 0.7385112047195435),\n",
              " ('sorry', 0.7095773816108704),\n",
              " ('me', 0.7072381973266602),\n",
              " ('nobody', 0.7045166492462158),\n",
              " ('yes', 0.7002850770950317),\n",
              " ('tomorrow', 0.6995285153388977),\n",
              " ('happened', 0.6980783939361572),\n",
              " ('everybody', 0.694588303565979)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKnt4zaftCLW",
        "colab_type": "code",
        "outputId": "3682d982-9b45-44c5-eb38-0447e9674bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        }
      },
      "source": [
        "df['Answer']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 [i, am, doing, well, how, about, you]\n",
              "1                                   [i, am, also, good]\n",
              "2                            [that, is, good, to, hear]\n",
              "3                                         [yes, it, is]\n",
              "4                                                  [hi]\n",
              "5                                [how, are, you, doing]\n",
              "6                                  [i, am, doing, well]\n",
              "7                            [that, is, good, to, hear]\n",
              "8                                         [yes, it, is]\n",
              "9                   [can, i, help, you, with, anything]\n",
              "10                          [yes, i, have, a, question]\n",
              "11                           [what, is, your, question]\n",
              "12                [could, i, borrow, a, cup, of, sugar]\n",
              "13           [i, am, sorry, but, i, do, not, have, any]\n",
              "14                                 [thank, you, anyway]\n",
              "15                                        [no, problem]\n",
              "16                [i, am, doing, well, how, about, you]\n",
              "17                                  [i, am, also, good]\n",
              "18                                     [that, is, good]\n",
              "19                                   [what, good, news]\n",
              "20                                  [i, can, not, read]\n",
              "21                [so, what, is, your, favorite, color]\n",
              "22                                               [blue]\n",
              "23    [who, who, is, but, a, form, following, the, f...\n",
              "24                               [what, are, you, then]\n",
              "25                                [a, man, in, a, mask]\n",
              "26                                  [i, can, see, that]\n",
              "27    [it, is, not, your, powers, of, observation, i...\n",
              "28                            [i, like, seeing, movies]\n",
              "29              [what, kind, of, movies, do, you, like]\n",
              "                            ...                        \n",
              "56             [complex, is, better, than, complicated]\n",
              "57                     [flat, is, better, than, nested]\n",
              "58                    [sparse, is, better, than, dense]\n",
              "59                                [readability, counts]\n",
              "60    [special, cases, are, not, special, enough, to...\n",
              "61              [although, practicality, beats, purity]\n",
              "62              [errors, should, never, pass, silently]\n",
              "63                       [unless, explicitly, silenced]\n",
              "64    [in, the, face, of, ambiguity, refuse, the, te...\n",
              "65    [there, should, be, one, and, preferably, only...\n",
              "66    [although, that, way, may, not, be, obvious, a...\n",
              "67                       [now, is, better, than, never]\n",
              "68    [although, never, is, often, better, than, rig...\n",
              "69    [if, the, implementation, is, hard, to, explai...\n",
              "70    [if, the, implementation, is, easy, to, explai...\n",
              "71    [namespaces, are, one, honking, great, idea, l...\n",
              "72                                           [i, agree]\n",
              "73                               [i, am, a, programmer]\n",
              "74            [what, languages, do, you, like, to, use]\n",
              "75         [i, use, python, java, and, c, quite, often]\n",
              "76              [i, use, python, quite, a, bit, myself]\n",
              "77             [i, am, not, incredibly, fond, of, java]\n",
              "78                                  [what, annoys, you]\n",
              "79                     [it, has, many, inconsistencies]\n",
              "80    [it, means, you, only, live, once, where, did,...\n",
              "81                        [i, heard, somebody, say, it]\n",
              "82                [it, depends, how, you, define, life]\n",
              "83    [life, is, the, condition, that, distinguishes...\n",
              "84           [is, that, a, definition, or, an, opinion]\n",
              "85                                [go, ahead, and, ask]\n",
              "Name: Answer, Length: 86, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VF6Ynv7to4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}