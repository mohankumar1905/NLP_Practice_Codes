{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n7SuYMTZClZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3168,
     "status": "ok",
     "timestamp": 1562139291441,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "mv9WYcrozC_L",
    "outputId": "02e43741-7e12-42f3-e531-e2add7cdb3fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDdEZ3K3Zcv5"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/My Drive/Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bOF7UDCcvJ9"
   },
   "outputs": [],
   "source": [
    "file=open('/content/drive/My Drive/Deep Learning/conversation.json')\n",
    "data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_mehlnzdKWE"
   },
   "outputs": [],
   "source": [
    "x = list()\n",
    "y = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-1j5XO_dn5E"
   },
   "outputs": [],
   "source": [
    "conversations = data['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqxyICVHeJes"
   },
   "outputs": [],
   "source": [
    "for conversation in conversations:\n",
    "  for position in range(len(conversation)):\n",
    "    if position < (len(conversation)-1):\n",
    "      x.append(conversation[position])\n",
    "      y.append(conversation[position+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPf1oRhxiMBD"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(x, y)), columns = ['Question' , 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udNsgmZH2YlA"
   },
   "outputs": [],
   "source": [
    "df['Answer'] = \"startseq \" + df['Answer'] + \" endseq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGis6BZjjEu-"
   },
   "outputs": [],
   "source": [
    "#Cleaning the Train Dataset\n",
    "df['Question'] = df['Question'].apply(lambda x: x.lower())\n",
    "df['Answer'] = df['Answer'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWMQZzNqUhJ"
   },
   "outputs": [],
   "source": [
    "df['Question']  = df['Question'].str.replace(\"won't\",\"will not\")\n",
    "df['Question']  = df['Question'].str.replace(\"ain't\",\"am not\")\n",
    "df['Question']  = df['Question'].str.replace(\"'s\",\" is\")\n",
    "df['Question']  = df['Question'].str.replace(\"'m\",\" am\")\n",
    "df['Question']  = df['Question'].str.replace(\"'re'\",\" are\")\n",
    "df['Question']  = df['Question'].str.replace(\"can't\",\"can not\")\n",
    "df['Question']  = df['Question'].str.replace(\"'ll\",\" will\")\n",
    "df['Question']  = df['Question'].str.replace(\"n't\",\" not\")\n",
    "\n",
    "df['Answer']  = df['Answer'].str.replace(\"won't\",\"will not\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"ain't\",\"am not\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'s\",\" is\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'m\",\" am\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'re'\",\" are\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"can't\",\"can not\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"'ll\",\" will\")\n",
    "df['Answer']  = df['Answer'].str.replace(\"n't\",\" not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdE3vGGwUeXW"
   },
   "outputs": [],
   "source": [
    "df['Question'] = df['Question'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x)) #removing all charecters except alphabets\n",
    "df['Question'] = df['Question'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces\n",
    "df['Answer'] = df['Answer'].apply(lambda x: re.sub('[^a-zA-z\\s]','',x)) #removing all charecters except alphabets\n",
    "df['Answer'] = df['Answer'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5LkPfhKEAg6"
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1ggOChBHdph"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"The num_words in Tokenizer, the maximum number of words to keep, based on word frequency. \n",
    "If num_words = 10000 Only the most common 9999 words will be kept. all he extra words will be removed.\"\"\"\n",
    "q_tokenizer = Tokenizer() #setting up tokenizer\n",
    "a_tokenizer = Tokenizer() \n",
    "q_tokenizer.fit_on_texts(df['Question']) #fitting tokenizer on dataframe \n",
    "a_tokenizer.fit_on_texts(df['Answer'])\n",
    "df['Question'] = q_tokenizer.texts_to_sequences(df['Question']) # removing least repeated words and converting them into sequence of numbers.\n",
    "df['Answer'] = a_tokenizer.texts_to_sequences(df['Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwWR5PXvd3Ey"
   },
   "outputs": [],
   "source": [
    "encoder_input = []\n",
    "decoder_input = []\n",
    "decoder_output = []\n",
    "for i in range(len(df['Question'])):\n",
    "  temp_list = []\n",
    "  for j in range(len(df['Answer'][i])):\n",
    "    if j < (len(df['Answer'][i])-1):\n",
    "      temp_list.append(df['Answer'][i][j])\n",
    "      encoder_input.append(df['Question'][i])\n",
    "      decoder_input.append((temp_list).copy())\n",
    "      decoder_output.append(df['Answer'][i][j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2482,
     "status": "ok",
     "timestamp": 1562139300578,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "wbcpWQVsEcNG",
    "outputId": "61dcfb97-3780-4f4d-e8e3-c6d8a23072f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good morning how are you</td>\n",
       "      <td>startseq i am doing well how about you endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am doing well how about you</td>\n",
       "      <td>startseq i am also good endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am also good</td>\n",
       "      <td>startseq that is good to hear endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that is good to hear</td>\n",
       "      <td>startseq yes it is endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello</td>\n",
       "      <td>startseq hi endseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Question                                         Answer\n",
       "0       good morning how are you  startseq i am doing well how about you endseq\n",
       "1  i am doing well how about you                 startseq i am also good endseq\n",
       "2                 i am also good           startseq that is good to hear endseq\n",
       "3           that is good to hear                      startseq yes it is endseq\n",
       "4                          hello                             startseq hi endseq"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2226,
     "status": "ok",
     "timestamp": 1562139300585,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "Xcqr41Tc0Z_P",
    "outputId": "9ebe37ce-40ba-4da0-90c7-0f8342de7856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoder Sequence Length Maximum\n",
    "encoder_sequence_length = max([len(x) for x in encoder_input])\n",
    "encoder_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1806,
     "status": "ok",
     "timestamp": 1562139300587,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "5bqQRuGD6aXz",
    "outputId": "9bc47e84-e2c0-4be0-d934-69a6a49482e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decoder Sequence Length Maximum\n",
    "decoder_sequence_length = max([len(x) for x in decoder_input])\n",
    "decoder_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn5OvYrMJvvM"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input,maxlen = encoder_sequence_length, padding='pre')\n",
    "decoder_input = pad_sequences(decoder_input,maxlen = decoder_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTEH_sHtLTRz"
   },
   "outputs": [],
   "source": [
    "num_classes = len(a_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aUX_qhbMPjz"
   },
   "outputs": [],
   "source": [
    "num_tokens = len(q_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1562139301930,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "hkvjwP-OKlP3",
    "outputId": "a1693a33-aba9-472e-cf57-d46479822dd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "decoder_output = to_categorical(decoder_output,num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1562139301931,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "fB9zahe8LrHw",
    "outputId": "f9dddfcd-cdea-40b6-b8a4-6dde8beeafce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((609, 28), (609, 29), (609, 221))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape,decoder_input.shape,decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1562139305245,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "mXMiUv85HpNi",
    "outputId": "f8cb9a84-cd87-4d5a-dc4d-3b0eb57b8585"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 07:35:05.232491 140182924056448 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0703 07:35:05.252631 140182924056448 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0703 07:35:05.428966 140182924056448 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Model Creation - Functional Type - Encoder\n",
    "# Define an input sequence and process it.\n",
    "encoder_Inputs = tf.keras.layers.Input(shape=(None,))\n",
    "encoder_embedding = tf.keras.layers.Embedding( num_tokens, 200 , mask_zero=True) (encoder_Inputs)\n",
    "encoder = tf.keras.layers.LSTM(256,return_state=True)\n",
    "encoder_outputs, hidden_state, cell_state = encoder(encoder_embedding)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [hidden_state, cell_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ntAYiISYsow"
   },
   "outputs": [],
   "source": [
    "#Model Creation - Functional Type - Decoder\n",
    "decoder_Inputs = tf.keras.layers.Input(shape=(None,))\n",
    "decoder_embedding = tf.keras.layers.Embedding( num_classes, 200 , mask_zero=True) (decoder_Inputs)\n",
    "decoder = tf.keras.layers.LSTM(256)\n",
    "decoder_outputs = decoder(decoder_embedding,initial_state = encoder_states)\n",
    "decoder_final_output = tf.keras.layers.Dense(num_classes, activation= 'softmax')(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZwkzcz1c8w0"
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "chatmodel = tf.keras.Model([encoder_Inputs, decoder_Inputs], decoder_final_output)\n",
    "chatmodel.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432,
     "status": "ok",
     "timestamp": 1562139307352,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "87k3vNsbde_y",
    "outputId": "877a66b8-bc61-4161-eac1-43870f38e046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 200)    41600       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 200)    44200       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 467968      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          467968      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 221)          56797       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,078,533\n",
      "Trainable params: 1,078,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chatmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24347,
     "status": "ok",
     "timestamp": 1562139331451,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "wXPG-eoGd2PU",
    "outputId": "ff638b9c-27fc-41a6-c0ca-956d1c65d7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "609/609 [==============================] - 2s 4ms/sample - loss: 5.3975\n",
      "Epoch 2/100\n",
      "609/609 [==============================] - 0s 336us/sample - loss: 5.3822\n",
      "Epoch 3/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 5.3634\n",
      "Epoch 4/100\n",
      "609/609 [==============================] - 0s 332us/sample - loss: 5.3320\n",
      "Epoch 5/100\n",
      "609/609 [==============================] - 0s 312us/sample - loss: 5.2697\n",
      "Epoch 6/100\n",
      "609/609 [==============================] - 0s 320us/sample - loss: 5.1305\n",
      "Epoch 7/100\n",
      "609/609 [==============================] - 0s 317us/sample - loss: 4.9694\n",
      "Epoch 8/100\n",
      "609/609 [==============================] - 0s 338us/sample - loss: 4.7935\n",
      "Epoch 9/100\n",
      "609/609 [==============================] - 0s 324us/sample - loss: 4.6396\n",
      "Epoch 10/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 4.5569\n",
      "Epoch 11/100\n",
      "609/609 [==============================] - 0s 310us/sample - loss: 4.5141\n",
      "Epoch 12/100\n",
      "609/609 [==============================] - 0s 337us/sample - loss: 4.4707\n",
      "Epoch 13/100\n",
      "609/609 [==============================] - 0s 351us/sample - loss: 4.4240\n",
      "Epoch 14/100\n",
      "609/609 [==============================] - 0s 308us/sample - loss: 4.3876\n",
      "Epoch 15/100\n",
      "609/609 [==============================] - 0s 328us/sample - loss: 4.3593\n",
      "Epoch 16/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 4.3319\n",
      "Epoch 17/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 4.3009\n",
      "Epoch 18/100\n",
      "609/609 [==============================] - 0s 305us/sample - loss: 4.2677\n",
      "Epoch 19/100\n",
      "609/609 [==============================] - 0s 340us/sample - loss: 4.2349\n",
      "Epoch 20/100\n",
      "609/609 [==============================] - 0s 332us/sample - loss: 4.2008\n",
      "Epoch 21/100\n",
      "609/609 [==============================] - 0s 311us/sample - loss: 4.1662\n",
      "Epoch 22/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 4.1362\n",
      "Epoch 23/100\n",
      "609/609 [==============================] - 0s 309us/sample - loss: 4.1038\n",
      "Epoch 24/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 4.0708\n",
      "Epoch 25/100\n",
      "609/609 [==============================] - 0s 315us/sample - loss: 4.0374\n",
      "Epoch 26/100\n",
      "609/609 [==============================] - 0s 325us/sample - loss: 4.0051\n",
      "Epoch 27/100\n",
      "609/609 [==============================] - 0s 320us/sample - loss: 3.9760\n",
      "Epoch 28/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 3.9394\n",
      "Epoch 29/100\n",
      "609/609 [==============================] - 0s 311us/sample - loss: 3.8998\n",
      "Epoch 30/100\n",
      "609/609 [==============================] - 0s 312us/sample - loss: 3.8637\n",
      "Epoch 31/100\n",
      "609/609 [==============================] - 0s 326us/sample - loss: 3.8261\n",
      "Epoch 32/100\n",
      "609/609 [==============================] - 0s 317us/sample - loss: 3.7866\n",
      "Epoch 33/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 3.7431\n",
      "Epoch 34/100\n",
      "609/609 [==============================] - 0s 329us/sample - loss: 3.6975\n",
      "Epoch 35/100\n",
      "609/609 [==============================] - 0s 333us/sample - loss: 3.6521\n",
      "Epoch 36/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 3.6039\n",
      "Epoch 37/100\n",
      "609/609 [==============================] - 0s 310us/sample - loss: 3.5542\n",
      "Epoch 38/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 3.5063\n",
      "Epoch 39/100\n",
      "609/609 [==============================] - 0s 325us/sample - loss: 3.4522\n",
      "Epoch 40/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 3.3926\n",
      "Epoch 41/100\n",
      "609/609 [==============================] - 0s 346us/sample - loss: 3.3395\n",
      "Epoch 42/100\n",
      "609/609 [==============================] - 0s 333us/sample - loss: 3.2767\n",
      "Epoch 43/100\n",
      "609/609 [==============================] - 0s 315us/sample - loss: 3.2143\n",
      "Epoch 44/100\n",
      "609/609 [==============================] - 0s 347us/sample - loss: 3.1541\n",
      "Epoch 45/100\n",
      "609/609 [==============================] - 0s 318us/sample - loss: 3.0937\n",
      "Epoch 46/100\n",
      "609/609 [==============================] - 0s 333us/sample - loss: 3.0292\n",
      "Epoch 47/100\n",
      "609/609 [==============================] - 0s 324us/sample - loss: 2.9633\n",
      "Epoch 48/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 2.9068\n",
      "Epoch 49/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 2.8384\n",
      "Epoch 50/100\n",
      "609/609 [==============================] - 0s 334us/sample - loss: 2.7767\n",
      "Epoch 51/100\n",
      "609/609 [==============================] - 0s 321us/sample - loss: 2.7119\n",
      "Epoch 52/100\n",
      "609/609 [==============================] - 0s 317us/sample - loss: 2.6462\n",
      "Epoch 53/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 2.5785\n",
      "Epoch 54/100\n",
      "609/609 [==============================] - 0s 327us/sample - loss: 2.5298\n",
      "Epoch 55/100\n",
      "609/609 [==============================] - 0s 333us/sample - loss: 2.4561\n",
      "Epoch 56/100\n",
      "609/609 [==============================] - 0s 321us/sample - loss: 2.3949\n",
      "Epoch 57/100\n",
      "609/609 [==============================] - 0s 310us/sample - loss: 2.3203\n",
      "Epoch 58/100\n",
      "609/609 [==============================] - 0s 314us/sample - loss: 2.2567\n",
      "Epoch 59/100\n",
      "609/609 [==============================] - 0s 320us/sample - loss: 2.1946\n",
      "Epoch 60/100\n",
      "609/609 [==============================] - 0s 337us/sample - loss: 2.1337\n",
      "Epoch 61/100\n",
      "609/609 [==============================] - 0s 318us/sample - loss: 2.0732\n",
      "Epoch 62/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 2.0211\n",
      "Epoch 63/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 1.9549\n",
      "Epoch 64/100\n",
      "609/609 [==============================] - 0s 335us/sample - loss: 1.8969\n",
      "Epoch 65/100\n",
      "609/609 [==============================] - 0s 340us/sample - loss: 1.8450\n",
      "Epoch 66/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 1.7827\n",
      "Epoch 67/100\n",
      "609/609 [==============================] - 0s 315us/sample - loss: 1.7287\n",
      "Epoch 68/100\n",
      "609/609 [==============================] - 0s 328us/sample - loss: 1.6811\n",
      "Epoch 69/100\n",
      "609/609 [==============================] - 0s 325us/sample - loss: 1.6243\n",
      "Epoch 70/100\n",
      "609/609 [==============================] - 0s 330us/sample - loss: 1.5663\n",
      "Epoch 71/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 1.5273\n",
      "Epoch 72/100\n",
      "609/609 [==============================] - 0s 313us/sample - loss: 1.4625\n",
      "Epoch 73/100\n",
      "609/609 [==============================] - 0s 328us/sample - loss: 1.4125\n",
      "Epoch 74/100\n",
      "609/609 [==============================] - 0s 321us/sample - loss: 1.3691\n",
      "Epoch 75/100\n",
      "609/609 [==============================] - 0s 354us/sample - loss: 1.3169\n",
      "Epoch 76/100\n",
      "609/609 [==============================] - 0s 323us/sample - loss: 1.2725\n",
      "Epoch 77/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 1.2245\n",
      "Epoch 78/100\n",
      "609/609 [==============================] - 0s 339us/sample - loss: 1.1759\n",
      "Epoch 79/100\n",
      "609/609 [==============================] - 0s 311us/sample - loss: 1.1346\n",
      "Epoch 80/100\n",
      "609/609 [==============================] - 0s 346us/sample - loss: 1.0891\n",
      "Epoch 81/100\n",
      "609/609 [==============================] - 0s 320us/sample - loss: 1.0451\n",
      "Epoch 82/100\n",
      "609/609 [==============================] - 0s 330us/sample - loss: 1.0085\n",
      "Epoch 83/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 0.9703\n",
      "Epoch 84/100\n",
      "609/609 [==============================] - 0s 315us/sample - loss: 0.9303\n",
      "Epoch 85/100\n",
      "609/609 [==============================] - 0s 328us/sample - loss: 0.8965\n",
      "Epoch 86/100\n",
      "609/609 [==============================] - 0s 331us/sample - loss: 0.8618\n",
      "Epoch 87/100\n",
      "609/609 [==============================] - 0s 305us/sample - loss: 0.8276\n",
      "Epoch 88/100\n",
      "609/609 [==============================] - 0s 332us/sample - loss: 0.7950\n",
      "Epoch 89/100\n",
      "609/609 [==============================] - 0s 322us/sample - loss: 0.7601\n",
      "Epoch 90/100\n",
      "609/609 [==============================] - 0s 308us/sample - loss: 0.7315\n",
      "Epoch 91/100\n",
      "609/609 [==============================] - 0s 339us/sample - loss: 0.7043\n",
      "Epoch 92/100\n",
      "609/609 [==============================] - 0s 309us/sample - loss: 0.6719\n",
      "Epoch 93/100\n",
      "609/609 [==============================] - 0s 336us/sample - loss: 0.6450\n",
      "Epoch 94/100\n",
      "609/609 [==============================] - 0s 307us/sample - loss: 0.6218\n",
      "Epoch 95/100\n",
      "609/609 [==============================] - 0s 321us/sample - loss: 0.5951\n",
      "Epoch 96/100\n",
      "609/609 [==============================] - 0s 319us/sample - loss: 0.5703\n",
      "Epoch 97/100\n",
      "609/609 [==============================] - 0s 320us/sample - loss: 0.5491\n",
      "Epoch 98/100\n",
      "609/609 [==============================] - 0s 309us/sample - loss: 0.5277\n",
      "Epoch 99/100\n",
      "609/609 [==============================] - 0s 311us/sample - loss: 0.5072\n",
      "Epoch 100/100\n",
      "609/609 [==============================] - 0s 309us/sample - loss: 0.4883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7e860094a8>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel.fit([encoder_input, decoder_input], decoder_output, batch_size=487, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXO4IooRPi2q"
   },
   "outputs": [],
   "source": [
    "index_word = dict([(index,word) for word, index in a_tokenizer.word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24904,
     "status": "ok",
     "timestamp": 1562139333517,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "oFv50MplqsTM",
    "outputId": "743b1c7a-cc1e-4772-a8a0-a6e0311d0443"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[np.argmax(chatmodel.predict([encoder_input[0:1], decoder_input[0:1]])[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23240,
     "status": "ok",
     "timestamp": 1562139333520,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "MEG2zgLrsEd1",
    "outputId": "910e869c-d1b9-47e5-a4c3-022ca8674b5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.68661891e-07, 1.53209066e-06, 1.26038913e-05, 3.04700916e-05,\n",
       "        9.00607090e-03, 5.03747333e-06, 3.54648109e-05, 1.08387438e-04,\n",
       "        9.17531142e-04, 2.59445951e-04, 9.08671856e-01, 3.80284519e-07,\n",
       "        4.29922147e-05, 3.37326037e-06, 1.30568182e-07, 6.28507347e-04,\n",
       "        1.32555622e-04, 3.75810341e-05, 3.06303045e-05, 1.40959062e-04,\n",
       "        5.17665067e-05, 2.61155537e-06, 1.54104564e-04, 8.03494549e-05,\n",
       "        3.41283367e-03, 3.82777507e-04, 2.13984633e-03, 6.98690928e-05,\n",
       "        4.25333055e-05, 1.26926752e-04, 4.72695456e-06, 2.89137489e-07,\n",
       "        4.57916111e-02, 2.06675706e-03, 2.86144336e-06, 7.48400589e-06,\n",
       "        2.99445470e-04, 6.95013223e-05, 7.50756044e-06, 6.28025082e-05,\n",
       "        1.62155322e-06, 9.65221943e-07, 5.26669737e-07, 1.12517818e-03,\n",
       "        4.11774468e-04, 4.30375667e-06, 2.48695794e-03, 5.59347609e-06,\n",
       "        2.52327212e-04, 2.96200765e-03, 2.91372459e-07, 9.57590510e-06,\n",
       "        1.37158167e-05, 5.19590321e-06, 1.70604073e-06, 1.11838585e-06,\n",
       "        3.44581031e-06, 3.44974956e-06, 4.28782660e-05, 1.50281503e-05,\n",
       "        1.68078634e-06, 7.36766367e-07, 5.62887408e-08, 1.82986327e-07,\n",
       "        3.39812061e-07, 3.77759352e-05, 1.29822465e-05, 2.43200617e-07,\n",
       "        1.41217328e-07, 1.22219535e-06, 1.17071318e-06, 5.41999179e-06,\n",
       "        4.77462663e-06, 1.54121553e-05, 2.33826563e-06, 1.66041971e-07,\n",
       "        2.41405633e-05, 5.57764452e-06, 6.33676100e-05, 3.99650344e-05,\n",
       "        5.55659411e-04, 6.05784010e-07, 2.28497578e-04, 1.57951750e-03,\n",
       "        1.54745180e-06, 2.96930716e-06, 6.57474564e-04, 1.05788176e-05,\n",
       "        4.06097206e-05, 7.81802646e-06, 1.83400320e-04, 3.09271745e-05,\n",
       "        3.01094205e-05, 4.14508213e-05, 1.35610719e-06, 2.39650717e-06,\n",
       "        6.78705546e-05, 8.66993196e-06, 1.91843592e-05, 3.10285532e-06,\n",
       "        2.21378946e-06, 6.92463027e-06, 3.04129743e-03, 6.66474307e-07,\n",
       "        1.16249043e-06, 1.75996538e-05, 2.82776386e-06, 1.25050724e-06,\n",
       "        3.52977139e-07, 9.70171300e-07, 6.61671322e-07, 2.98040419e-07,\n",
       "        1.46968332e-05, 9.59208875e-04, 7.77161331e-05, 8.32898295e-05,\n",
       "        3.31602781e-03, 2.61916575e-04, 6.42519808e-07, 3.66959057e-07,\n",
       "        2.55807536e-04, 3.27167072e-05, 5.67488096e-05, 3.33291354e-07,\n",
       "        7.91260391e-08, 7.20164678e-07, 3.73157013e-06, 1.66891562e-06,\n",
       "        2.37058592e-03, 3.78910336e-05, 1.82820459e-05, 1.57913128e-05,\n",
       "        1.05720098e-07, 7.31617945e-07, 1.19872061e-06, 4.68151382e-04,\n",
       "        2.76607602e-06, 9.96743097e-07, 9.78310695e-08, 1.24581320e-05,\n",
       "        2.24273080e-07, 1.09871353e-05, 3.23207416e-07, 2.91630458e-05,\n",
       "        2.68112876e-06, 2.54149763e-05, 9.69027496e-07, 2.24352993e-06,\n",
       "        1.13129863e-05, 6.93136326e-06, 2.19698472e-06, 2.41400983e-07,\n",
       "        2.83000446e-07, 3.95620082e-05, 1.18644148e-05, 9.49634284e-07,\n",
       "        9.19581453e-06, 2.07276025e-06, 4.13893957e-07, 3.29692521e-05,\n",
       "        1.23627269e-05, 3.71345391e-06, 2.48370355e-07, 3.99036736e-07,\n",
       "        1.38895430e-07, 9.10997983e-07, 2.14643038e-07, 7.50676122e-07,\n",
       "        1.82795503e-07, 8.62305001e-07, 3.14122121e-06, 3.86571259e-07,\n",
       "        2.73632168e-07, 5.08526625e-07, 5.92727588e-07, 3.34273011e-07,\n",
       "        1.63953679e-04, 5.41218506e-05, 4.49507177e-04, 7.93329605e-07,\n",
       "        5.45396745e-07, 1.35024459e-06, 1.10396086e-05, 3.63147137e-06,\n",
       "        2.20855673e-05, 1.01943195e-04, 2.60671968e-05, 9.75009789e-06,\n",
       "        1.77661332e-05, 3.37995999e-07, 5.13357861e-07, 1.92154474e-07,\n",
       "        7.23444828e-07, 8.15555220e-04, 5.43957394e-05, 7.19620584e-06,\n",
       "        2.59026390e-04, 1.60919819e-06, 1.64163635e-06, 5.73159298e-07,\n",
       "        1.38560836e-07, 3.88182372e-07, 1.40726613e-07, 1.65767617e-07,\n",
       "        1.88980650e-07, 6.45534840e-07, 3.63685871e-07, 4.57547600e-07,\n",
       "        1.82863778e-06, 1.14102068e-06, 7.35608637e-07, 4.72325240e-07,\n",
       "        1.16360729e-06, 6.40141195e-07, 1.31887168e-06, 6.60617047e-07,\n",
       "        7.45650254e-07, 3.84988908e-07, 1.10636458e-04, 7.02359015e-04,\n",
       "        3.12100292e-06]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatmodel.predict([encoder_input[0:1], decoder_input[1:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdodBucDhVJm"
   },
   "outputs": [],
   "source": [
    "predicted = chatmodel.predict([encoder_input[0:1], decoder_input[0:1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20130,
     "status": "ok",
     "timestamp": 1562139333529,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "ENWdPOjLqqVl",
    "outputId": "07dd0e5b-0fca-4f81-dcf7-6a8405050bf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('startseq', 4.2871773e-07),\n",
       " ('endseq', 3.0892413e-06),\n",
       " ('is', 4.787392e-05),\n",
       " ('i', 0.89737684),\n",
       " ('you', 7.978773e-06),\n",
       " ('it', 0.00025416716),\n",
       " ('the', 5.963321e-05),\n",
       " ('a', 0.0029208963),\n",
       " ('what', 0.0053994786),\n",
       " ('am', 0.0022286035),\n",
       " ('to', 4.417247e-07),\n",
       " ('of', 1.3232672e-05),\n",
       " ('better', 5.8246746e-07),\n",
       " ('than', 2.4898847e-07),\n",
       " ('that', 0.0016448073),\n",
       " ('do', 0.00031943247),\n",
       " ('good', 3.408443e-05),\n",
       " ('are', 0.0004114621),\n",
       " ('not', 7.454944e-06),\n",
       " ('how', 0.00040587567),\n",
       " ('your', 6.8487793e-07),\n",
       " ('but', 2.5210538e-05),\n",
       " ('like', 2.2653412e-05),\n",
       " ('doing', 0.00010663373),\n",
       " ('yes', 0.052046634),\n",
       " ('in', 0.00032499855),\n",
       " ('complex', 0.00036114446),\n",
       " ('and', 3.4929121e-06),\n",
       " ('well', 7.2350394e-06),\n",
       " ('about', 8.317091e-06),\n",
       " ('hear', 3.6476658e-07),\n",
       " ('can', 0.0023233446),\n",
       " ('who', 0.00865391),\n",
       " ('tell', 1.46612e-06),\n",
       " ('know', 2.4988706e-06),\n",
       " ('complicated', 0.00012641241),\n",
       " ('python', 1.6902006e-05),\n",
       " ('although', 0.00016257036),\n",
       " ('never', 4.5591023e-06),\n",
       " ('be', 3.2911143e-07),\n",
       " ('one', 3.4817992e-07),\n",
       " ('idea', 6.0078906e-07),\n",
       " ('use', 0.00014438196),\n",
       " ('also', 6.438323e-06),\n",
       " ('with', 5.053384e-07),\n",
       " ('have', 9.629302e-05),\n",
       " ('question', 4.5886262e-07),\n",
       " ('no', 0.0051781707),\n",
       " ('man', 0.0005144277),\n",
       " ('me', 9.867557e-07),\n",
       " ('movies', 5.1288557e-06),\n",
       " ('youre', 0.00052741304),\n",
       " ('all', 7.470423e-06),\n",
       " ('cake', 8.0547034e-07),\n",
       " ('delicious', 9.795409e-07),\n",
       " ('or', 8.812784e-06),\n",
       " ('want', 6.1733584e-07),\n",
       " ('simple', 4.924413e-05),\n",
       " ('face', 2.8609636e-06),\n",
       " ('ambiguity', 9.029455e-07),\n",
       " ('refuse', 4.7518853e-07),\n",
       " ('temptation', 1.7833781e-07),\n",
       " ('guess', 5.314434e-07),\n",
       " ('special', 6.1879587e-07),\n",
       " ('should', 3.602458e-05),\n",
       " ('unless', 0.00012874951),\n",
       " ('only', 2.2611308e-08),\n",
       " ('obvious', 1.0897944e-07),\n",
       " ('way', 1.0309523e-06),\n",
       " ('may', 1.6364878e-06),\n",
       " ('now', 6.5488835e-05),\n",
       " ('often', 1.4944522e-06),\n",
       " ('if', 0.00012711031),\n",
       " ('implementation', 6.0175415e-07),\n",
       " ('explain', 2.4638115e-07),\n",
       " ('java', 1.1827284e-05),\n",
       " ('quite', 1.6340177e-06),\n",
       " ('life', 0.0025870847),\n",
       " ('hi', 0.0003354333),\n",
       " ('help', 8.037801e-06),\n",
       " ('anything', 9.593269e-07),\n",
       " ('could', 0.0031104079),\n",
       " ('borrow', 9.035369e-06),\n",
       " ('cup', 2.5129788e-07),\n",
       " ('sugar', 5.0213966e-06),\n",
       " ('sorry', 3.480149e-05),\n",
       " ('any', 2.8100835e-06),\n",
       " ('thank', 0.00055692345),\n",
       " ('anyway', 2.8553364e-07),\n",
       " ('problem', 0.00013384741),\n",
       " ('news', 3.906046e-06),\n",
       " ('read', 2.5741933e-06),\n",
       " ('so', 0.00040420756),\n",
       " ('favorite', 2.2867603e-07),\n",
       " ('color', 9.269784e-07),\n",
       " ('blue', 0.0006358898),\n",
       " ('form', 4.3058435e-06),\n",
       " ('following', 6.8385625e-06),\n",
       " ('function', 1.9790177e-06),\n",
       " ('then', 2.666247e-07),\n",
       " ('mask', 1.1519172e-06),\n",
       " ('see', 0.00028072365),\n",
       " ('powers', 1.7218231e-07),\n",
       " ('observation', 2.6735204e-06),\n",
       " ('doubt', 6.175705e-06),\n",
       " ('merely', 2.8286738e-06),\n",
       " ('paradoxical', 1.0287297e-06),\n",
       " ('nature', 4.397626e-07),\n",
       " ('asking', 3.8041865e-06),\n",
       " ('masked', 2.7043967e-07),\n",
       " ('music', 1.8672753e-07),\n",
       " ('seeing', 2.4651317e-06),\n",
       " ('kind', 0.0003734083),\n",
       " ('alice', 0.0010540297),\n",
       " ('wonderland', 2.1234252e-06),\n",
       " ('wish', 9.881213e-05),\n",
       " ('was', 1.0002519e-05),\n",
       " ('mad', 1.1032959e-07),\n",
       " ('hatter', 2.03289e-07),\n",
       " ('entirely', 2.1995e-05),\n",
       " ('bonkers', 4.105621e-06),\n",
       " ('will', 5.9907984e-06),\n",
       " ('secret', 1.2493851e-07),\n",
       " ('best', 1.0678122e-07),\n",
       " ('people', 9.79002e-07),\n",
       " ('working', 3.1106467e-07),\n",
       " ('on', 2.530578e-07),\n",
       " ('baking', 3.1280466e-05),\n",
       " ('else', 6.227618e-05),\n",
       " ('nothing', 6.952938e-05),\n",
       " ('something', 5.699791e-06),\n",
       " ('self', 1.596473e-08),\n",
       " ('robot', 1.2459228e-07),\n",
       " ('work', 3.7294953e-07),\n",
       " ('its', 0.0053314297),\n",
       " ('seems', 7.339793e-06),\n",
       " ('familiar', 6.592681e-08),\n",
       " ('zen', 2.8559723e-08),\n",
       " ('beautiful', 7.415467e-05),\n",
       " ('ugly', 3.1833173e-07),\n",
       " ('explicit', 3.7118705e-05),\n",
       " ('implicit', 1.07162776e-07),\n",
       " ('flat', 7.117543e-05),\n",
       " ('nested', 6.168909e-07),\n",
       " ('sparse', 0.00012287755),\n",
       " ('dense', 4.0928197e-07),\n",
       " ('readability', 6.927921e-06),\n",
       " ('counts', 2.2693728e-06),\n",
       " ('cases', 5.318102e-06),\n",
       " ('enough', 8.5602727e-07),\n",
       " ('break', 1.5973023e-07),\n",
       " ('rules', 2.8450182e-07),\n",
       " ('practicality', 6.1034184e-06),\n",
       " ('beats', 5.4416034e-07),\n",
       " ('purity', 1.17110815e-07),\n",
       " ('errors', 7.2869705e-05),\n",
       " ('pass', 1.5733149e-06),\n",
       " ('silently', 2.1084533e-07),\n",
       " ('explicitly', 1.0897655e-05),\n",
       " ('silenced', 4.0285133e-07),\n",
       " ('there', 1.2977422e-05),\n",
       " ('preferably', 4.946438e-08),\n",
       " ('at', 2.904237e-07),\n",
       " ('first', 1.9096215e-07),\n",
       " ('dutch', 1.4720941e-06),\n",
       " ('right', 2.17799e-07),\n",
       " ('hard', 2.9471292e-07),\n",
       " ('bad', 1.1996855e-07),\n",
       " ('easy', 1.4400318e-07),\n",
       " ('namespaces', 8.307296e-05),\n",
       " ('honking', 2.1324261e-07),\n",
       " ('great', 8.869038e-08),\n",
       " ('let', 2.6949016e-07),\n",
       " ('more', 7.3171725e-07),\n",
       " ('those', 7.126006e-07),\n",
       " ('agree', 1.923309e-05),\n",
       " ('programmer', 8.9930853e-07),\n",
       " ('languages', 0.00013854126),\n",
       " ('c', 6.042983e-07),\n",
       " ('bit', 1.4044817e-07),\n",
       " ('myself', 6.058803e-08),\n",
       " ('incredibly', 1.9215627e-06),\n",
       " ('fond', 1.3433424e-06),\n",
       " ('annoys', 3.2281972e-05),\n",
       " ('has', 5.515581e-05),\n",
       " ('many', 2.1929097e-06),\n",
       " ('inconsistencies', 1.1865147e-06),\n",
       " ('means', 1.19331835e-05),\n",
       " ('live', 8.671571e-08),\n",
       " ('once', 5.0281125e-07),\n",
       " ('where', 3.6508467e-07),\n",
       " ('did', 5.179946e-07),\n",
       " ('heard', 6.663594e-05),\n",
       " ('somebody', 4.4206245e-06),\n",
       " ('say', 2.6959083e-06),\n",
       " ('depends', 0.00013982333),\n",
       " ('define', 3.356717e-07),\n",
       " ('condition', 5.0723156e-07),\n",
       " ('distinguishes', 4.3957897e-07),\n",
       " ('organisms', 2.2999706e-07),\n",
       " ('from', 7.0490466e-07),\n",
       " ('inorganic', 2.586427e-07),\n",
       " ('matter', 7.8506594e-07),\n",
       " ('including', 3.4450932e-07),\n",
       " ('capacity', 5.9546085e-07),\n",
       " ('for', 3.7451096e-07),\n",
       " ('growth', 2.8586388e-07),\n",
       " ('reproduction', 1.0142412e-06),\n",
       " ('functional', 1.6260849e-06),\n",
       " ('activity', 4.9397937e-07),\n",
       " ('continual', 1.6339156e-07),\n",
       " ('change', 8.9202507e-07),\n",
       " ('preceding', 5.323651e-07),\n",
       " ('death', 1.2170291e-06),\n",
       " ('definition', 2.8699148e-07),\n",
       " ('an', 6.5571953e-07),\n",
       " ('opinion', 6.5421165e-07),\n",
       " ('go', 0.0014626582),\n",
       " ('ahead', 3.8539416e-05),\n",
       " ('ask', 2.3231416e-07)]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = list()\n",
    "for i in index_word:\n",
    "  temp_list.append((index_word[i],predicted[i]))\n",
    "temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18833,
     "status": "ok",
     "timestamp": 1562139333530,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "W2vN1LPDh1u7",
    "outputId": "52210fae-8967-400f-a2c0-0ac8d27d5fa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17878,
     "status": "ok",
     "timestamp": 1562139333532,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "PjTExm2pjPhD",
    "outputId": "8b21e3f1-048e-4450-baf4-cf559ea01403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15348,
     "status": "ok",
     "timestamp": 1562139333532,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "UA-5NOdDmLW4",
    "outputId": "a64f477e-2acf-479b-a121-7752ee77fd25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sequence = a_tokenizer.texts_to_sequences([\"startseq\"])[0]\n",
    "pad_sequences([decoder_sequence],maxlen=29,padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yM35aKUgryur"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "import tensorflow as tf\n",
    "class Beam(object):\n",
    "    \"\"\"\n",
    "    For comparison of prefixes, the tuple (prefix_prob, complete_sentence) is uesd.\n",
    "    This is so that if two prefixes have eequal probabilities then a complete sentence is preffered\n",
    "    over and incomplete one since (0.5, False) < (0.5, True)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, beam_width):\n",
    "        self.heap = []\n",
    "        self.beam_width = beam_width\n",
    "    \n",
    "    def add(self, prob, complete, prefix):\n",
    "        heapq.heappush(self.heap, (prob, complete, prefix))\n",
    "\n",
    "        # if we exeed the beam size, remove the \"worst\" item\n",
    "        if len(self.heap) > self.beam_width:\n",
    "            heapq.heappop(self.heap)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.heap)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.heap)\n",
    "      \n",
    "def beamsearch(probabilities_function, encoder_input, start_word, encoder_tokenizer, question_length, decoder_tokenizer, index_to_word_dict, model, beam_width=3, clip_len=-1, Question_Padding= \"pre\"):\n",
    "    # Probablities Function- Function which output the probablity of each word predicted.\n",
    "    prev_beam = Beam(beam_width)\n",
    "    prev_beam.add(1.0, False, [ start_word ])\n",
    "    encoder_sequence = encoder_tokenizer.texts_to_sequences([encoder_input])[0]\n",
    "    encoder_sequence = pad_sequences([encoder_sequence],maxlen=question_length,padding=Question_Padding)\n",
    "    while True:\n",
    "        curr_beam = Beam(beam_width)\n",
    "         \n",
    "        #Add complete sentences that do not yet have the best probability to the current beam, the rest prepare to add more words to them.\n",
    "        for (prefix_prob, complete, prefix) in prev_beam:\n",
    "            if complete == True:\n",
    "                curr_beam.add(prefix_prob, True, prefix)\n",
    "            else:\n",
    "                #Get probability of each possible next word for the incomplete prefix.\n",
    "                for (next_prob, next_word) in probabilities_function(encoder_sequence, prefix, decoder_tokenizer, index_to_word_dict, model):\n",
    "                    if next_word == 'endseq': #if next word is the end token then mark prefix as complete and leave out the end token\n",
    "                        curr_beam.add(prefix_prob*next_prob, True, prefix)\n",
    "                    else: #if next word is a non-end token then mark prefix as incomplete\n",
    "                        curr_beam.add(prefix_prob*next_prob, False, prefix+[next_word])\n",
    "         \n",
    "        (best_prob, best_complete, best_prefix) = max(curr_beam)\n",
    "        if best_complete == True or len(best_prefix)-1 == clip_len: #if most probable prefix is a complete sentence or has a length that exceeds the clip length (ignoring the start token) then return it\n",
    "            return (best_prefix[1:], best_prob) #return best sentence without the start token and together with its probability\n",
    "             \n",
    "        prev_beam = curr_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rw9a_Zf_lUEg"
   },
   "outputs": [],
   "source": [
    "# beam search\n",
    "def beam_search_decoder_single_word_probabilities_function(encoder_sequence,decoder_word, decoder_tokenizer, index_to_word_dict, model):\n",
    "  decoder_sequence = decoder_tokenizer.texts_to_sequences([decoder_word])[0]\n",
    "  decoder_sequence = pad_sequences([decoder_sequence],maxlen=29,padding=\"pre\") \n",
    "\t\n",
    "  predicted = model.predict([encoder_sequence, decoder_sequence])[0]\n",
    "  probablity_word_tuple_list = list()\n",
    "  for i in index_word:\n",
    "    probablity_word_tuple_list.append((predicted[i],index_word[i]))\n",
    "  return probablity_word_tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1951,
     "status": "ok",
     "timestamp": 1562140209452,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "fiBELFle0jkX",
    "outputId": "7ef93e08-a71a-4952-9182-2c1b9e282791"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i', 'can', 'not', 'read'], 0.14852316276359784)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beamsearch(beam_search_decoder_single_word_probabilities_function, \"what is your favorite book\", 'startseq', q_tokenizer, 30, a_tokenizer, index_word, chatmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG-q10OowTn9"
   },
   "outputs": [],
   "source": [
    "# beamsearch(probabilities_function, encoder_input, start_word, encoder_tokenizer, question_length, decoder_tokenizer, index_to_word_dict, model, beam_width=3, clip_len=-1, Question_Padding= \"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1559459309028,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "N1nDYKMN5PqT",
    "outputId": "3427d71b-5e90-4c80-9e03-6642752b095c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99933535 i\n",
      "0.00018951378 yes\n",
      "0.00018746688 how\n"
     ]
    }
   ],
   "source": [
    "index_list = predicted.argsort()[-3:][::-1]\n",
    "for i in index_list:\n",
    "  print(predicted[i],index_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1559459991863,
     "user": {
      "displayName": "Mohankumar Balasubramaniyam",
      "photoUrl": "https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg",
      "userId": "03872728872081242131"
     },
     "user_tz": -330
    },
    "id": "facrVt-fA56M",
    "outputId": "3b4a01e0-34bd-4394-8882-8f133fcdbbd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  1,  4, 10, 24, 29, 20, 30,  5,  2]],\n",
       "       dtype=int32),\n",
       " array([[ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  4, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  4, 10, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  4, 10, 24, 29,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  4, 10, 24, 29, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)]"
      ]
     },
     "execution_count": 243,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoder_input[0:1], decoder_input[0:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFKWn_VBDXOW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ChatBot_Beam_Search.ipynb",
   "provenance": [
    {
     "file_id": "1VxJDG321zDAnIaNBH1WY2GkZWeU13Eqv",
     "timestamp": 1559444076443
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
