{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_classification_pytorch_lstm_level2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARTq2oijAtIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "246f547b-c55c-4d9a-b912-4207e49f048a"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusdsAIJAugX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path =  \"/content/drive/My Drive/Movie_Reviews/csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugxCqyypA8Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchtext\n",
        "import spacy\n",
        "import time\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset, LabelField"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqiZ3BgF7oY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "691a3a8b-09e1-44c1-9bf6-2027c2b408e7"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLeuelX3_myt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1994\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P6zW_zuK67T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e9ced040-8faf-4ef4-880f-b79a529e013f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIkWSqXlBWH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(f\"{path}/train.csv\")\n",
        "test_df = pd.read_csv(f\"{path}/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIGOYqfiBb6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3f1bffa4-4634-4d36-a6d2-84d76b7571ef"
      },
      "source": [
        "print(f'Number of training examples: {len(train_df)}')\n",
        "print(f'Number of testing examples: {len(test_df)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF8hstRbC-lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d503f40a-180c-406f-b623-180f1cf0f1f5"
      },
      "source": [
        "train_split, val_split = train_test_split(train_df, test_size=0.3, random_state=1994)\n",
        "train_split.shape, val_split.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 2), (7500, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVz0iAzEfR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split.to_csv(f\"{path}/train_split.csv\", index=False)\n",
        "val_split.to_csv(f\"{path}/val_split.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Vkc00sNP5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = spacy.load('en')\n",
        "def tokenize(sentence):\n",
        "  return [tok.text for tok in en.tokenizer(sentence)]\n",
        "spacy_tokenizer = Field(tokenize=tokenize, include_lengths=True)\n",
        "LABEL = LabelField(dtype = torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw0bSOy3NQAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "29cb42c1-8bda-424a-85ab-16d4c220e674"
      },
      "source": [
        "tokenize(\"i don't love you\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'do', \"n't\", 'love', 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TazS1OXxNQKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# associate the text in the 'English' column with the EN_TEXT field, #\n",
        "data_fields = [('reviews', spacy_tokenizer), ('pos_or_neg', LABEL)]\n",
        "train, val, test = TabularDataset.splits(path=path, train='train_split.csv', validation='val_split.csv',\n",
        "                                         test='test.csv', format='csv', skip_header=True, fields=data_fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zePvw1A7NQQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a2c8626a-d423-48da-bb23-fe7efdb6daba"
      },
      "source": [
        "print(f'Number of training examples: {len(train)}')\n",
        "print(f'Number of testing examples: {len(val)}')\n",
        "print(f'Number of training examples: {len(test)}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of testing examples: 7500\n",
            "Number of training examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-ChmQLBNQIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0989b0e7-40a0-4f35-a05b-9420870de102"
      },
      "source": [
        "print(vars(train.examples[0])), print(vars(val.examples[0])), print(vars(test.examples[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'reviews': ['When', 'will', 'the', 'hurting', 'stop', '?', 'I', 'never', 'want', 'to', 'see', 'another', 'version', 'of', 'a', 'Christmas', 'Carol', 'again', '.', 'They', 'keep', 'on', 'making', 'movies', 'with', 'the', 'same', 'story', ',', 'falling', 'over', 'each', 'other', 'in', 'trying', 'to', 'make', 'the', 'movie', 'better', 'then', 'the', 'rest', ',', 'but', 'sadly', 'fail', 'to', 'do', 'so', ',', 'as', 'this', 'is', 'not', 'a', 'good', 'story', '.', 'Moralistic', ',', 'old', '-', 'fashioned', ',', 'conservative', 'happy', '-', 'thinking', '.', 'As', 'if', 'people', 'learn', '.', 'The', 'numerous', 'different', 'versions', 'of', 'this', 'film', 'prove', 'that', 'we', 'donÂ´t', '.'], 'pos_or_neg': '0'}\n",
            "{'reviews': ['Kol', ',', 'space', 'prisoner', 'on', 'space', 'death', 'row', ',', 'manages', 'to', 'hijack', 'a', 'space', 'shuttle', 'and', 'escape', 'to', 'the', 'woods', 'of', 'America', 'where', 'he', ',', 'along', 'with', 'some', 'new', 'found', 'friend', 'try', 'to', 'escape', 'from', 'the', \"'\", 'Alienator', '\"', 'a', 'female', 'cyborg', 'killing', 'machine', '.', 'Made', 'one', 'year', 'after', 'the', 'best', 'movie', 'of', 'Fred', 'Olen', 'Ray', \"'s\", 'career', ',', '\"', 'Hollywood', 'Chainsaw', 'Hookers', '\"', ',', 'this', 'one', 'ca', \"n't\", 'help', 'but', 'feel', 'like', 'a', 'bit', 'of', 'a', 'letdown', '.', 'Just', 'as', 'low', '-', 'budget', 'as', 'that', 'earlier', 'film', ',', 'but', 'not', 'nearly', 'as', 'fun', 'as', 'I', 'had', 'with', 'it', '.', 'None', 'of', 'the', 'actors', 'really', 'stood', 'out', 'at', 'me', '.', 'The', 'film', 'is', 'alright', 'for', 'the', 'undiscriminating', 'viewer', 'during', 'a', 'rainy', 'Saturday', 'afternoon', ',', 'but', 'that', \"'s\", 'pretty', 'much', 'all', 'it', \"'s\", 'good', 'for.<br', '/><br', '/>My', 'Grade', ':', 'D+', '<', 'br', '/><br', '/>Where', 'i', 'saw', 'it', ':', 'Showtime', 'Thriller'], 'pos_or_neg': '0'}\n",
            "{'reviews': ['I', 'went', 'and', 'saw', 'this', 'movie', 'last', 'night', 'after', 'being', 'coaxed', 'to', 'by', 'a', 'few', 'friends', 'of', 'mine', '.', 'I', \"'ll\", 'admit', 'that', 'I', 'was', 'reluctant', 'to', 'see', 'it', 'because', 'from', 'what', 'I', 'knew', 'of', 'Ashton', 'Kutcher', 'he', 'was', 'only', 'able', 'to', 'do', 'comedy', '.', 'I', 'was', 'wrong', '.', 'Kutcher', 'played', 'the', 'character', 'of', 'Jake', 'Fischer', 'very', 'well', ',', 'and', 'Kevin', 'Costner', 'played', 'Ben', 'Randall', 'with', 'such', 'professionalism', '.', 'The', 'sign', 'of', 'a', 'good', 'movie', 'is', 'that', 'it', 'can', 'toy', 'with', 'our', 'emotions', '.', 'This', 'one', 'did', 'exactly', 'that', '.', 'The', 'entire', 'theater', '(', 'which', 'was', 'sold', 'out', ')', 'was', 'overcome', 'by', 'laughter', 'during', 'the', 'first', 'half', 'of', 'the', 'movie', ',', 'and', 'were', 'moved', 'to', 'tears', 'during', 'the', 'second', 'half', '.', 'While', 'exiting', 'the', 'theater', 'I', 'not', 'only', 'saw', 'many', 'women', 'in', 'tears', ',', 'but', 'many', 'full', 'grown', 'men', 'as', 'well', ',', 'trying', 'desperately', 'not', 'to', 'let', 'anyone', 'see', 'them', 'crying', '.', 'This', 'movie', 'was', 'great', ',', 'and', 'I', 'suggest', 'that', 'you', 'go', 'see', 'it', 'before', 'you', 'judge', '.'], 'pos_or_neg': '1'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yxYDC8qZM5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv-PKlmXaAM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "49715933-9ee1-41b3-cd80-77b0aa51d7b2"
      },
      "source": [
        "spacy_tokenizer.build_vocab(train, max_size=MAX_VOCAB_SIZE, vectors=\"glove.6B.100d\", unk_init=torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(spacy_tokenizer.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqjhyFA7adPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6b8382c7-598f-4215-ab12-e807e6838108"
      },
      "source": [
        "print(spacy_tokenizer.vocab.freqs.most_common(20))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 202228), (',', 191811), ('.', 166104), ('a', 109545), ('and', 109108), ('of', 100261), ('to', 93586), ('is', 76219), ('in', 61112), ('I', 53952), ('it', 53535), ('that', 49080), ('\"', 44472), (\"'s\", 43144), ('this', 42114), ('-', 36966), ('/><br', 35439), ('was', 34960), ('as', 30261), ('with', 30017)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9EQPJQIaAJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e3e3b4e8-2962-47b7-e198-548f9265f9c2"
      },
      "source": [
        "print(spacy_tokenizer.vocab.itos[:10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1JnVMosaAGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9413a9d5-9e49-4dcd-8e0f-6729a977d476"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f1810e9e840>, {'0': 0, '1': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v44ABIrbiik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, val, test),\n",
        "                                      sort_key=lambda x: len(x.reviews), batch_size=BATCH_SIZE, device=device, sort_within_batch=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUkLZRZPFbzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_rnn_layers, bidirectional, dropout, pad_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_rnn_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "    if bidirectional:\n",
        "      self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "    else:\n",
        "      self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    #text -> [Sentence Length, batch_size]\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "    #embedded will be [sentence length, batch_size, embedding_dim]\n",
        "    #pack sequence\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "    packed_output, (hidden , cell) = self.lstm(packed_embedded)\n",
        "\n",
        "    #unpack sequence\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "    #output -> [sentence length, batch size, hidden dimensions*num directions]\n",
        "    #hidden = [num layers * num directions, batch size, hid dim]\n",
        "    #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "    #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n",
        "    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "\n",
        "    #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "    return self.fc(hidden)\n",
        "\n",
        "  def predict(self, text, text_lengths):\n",
        "    return self(text, text_lengths).squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBcAlDMWIZfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 25002\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = spacy_tokenizer.vocab.stoi[spacy_tokenizer.pad_token]\n",
        "model = CustomLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S9Nz6z4I5Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "63cf534a-2559-404c-cba7-f971997b87fe"
      },
      "source": [
        "def count_trainable_parameters(model):\n",
        "  return sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "print(f\"The model has {count_trainable_parameters(model)} trainable parameters\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4810857 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMU48mx5Uw00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "80eb2526-a70b-4b39-a7cf-a472ddae29fe"
      },
      "source": [
        "pretrained_embeddings = spacy_tokenizer.vocab.vectors\n",
        "pretrained_embeddings.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25002, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nzG-DKwU93h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "6b38be2c-bdb4-4e6d-f2db-36ce9450c981"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8663, -0.1668, -0.3368,  ...,  0.3293, -0.4030, -0.7492],\n",
              "        [-0.0711, -1.6034, -0.4121,  ...,  2.0934, -0.0031, -0.3947],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.5610,  0.2996,  0.2498,  ..., -0.6200,  0.1011,  0.9162],\n",
              "        [ 0.0701,  0.4941,  0.1676,  ...,  0.1009, -0.4823,  0.4224],\n",
              "        [ 2.6203, -0.4006, -0.8117,  ..., -2.3390,  0.5394, -0.2738]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36HorAjZVZ8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5194c3c2-8e66-4afc-b630-8ba8d68006e8"
      },
      "source": [
        "UNK_IDX = spacy_tokenizer.vocab.stoi[spacy_tokenizer.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.5610,  0.2996,  0.2498,  ..., -0.6200,  0.1011,  0.9162],\n",
            "        [ 0.0701,  0.4941,  0.1676,  ...,  0.1009, -0.4823,  0.4224],\n",
            "        [ 2.6203, -0.4006, -0.8117,  ..., -2.3390,  0.5394, -0.2738]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c56_ZoP-JzGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g4T5OjDKnwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "loss_criterion = loss_criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBczBTZ7NL_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, target):\n",
        "  \"\"\"Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\"\"\"\n",
        "  #rounds prediction to the closest integer.\n",
        "  rounded_prediction = torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_prediction == target).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj2km9J7gMRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    reviews, review_length = batch.reviews\n",
        "    predictions = model.predict(reviews, review_length)#.squeeze(1)\n",
        "    loss = criterion(predictions, batch.pos_or_neg)\n",
        "    acc = binary_accuracy(predictions, batch.pos_or_neg)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JZoes6lgplO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  #with torch.no_grad():\n",
        "  for batch in iterator:\n",
        "    reviews, review_length = batch.reviews\n",
        "    predictions = model.predict(reviews, review_length)#.squeeze(1)\n",
        "    loss = criterion(predictions, batch.pos_or_neg)\n",
        "    acc = binary_accuracy(predictions, batch.pos_or_neg)\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vuKWEdFkaTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yveNMZJRg1XZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "e2e54895-e0b3-4663-ecce-4e7cad0a49b8"
      },
      "source": [
        "num_epochs = 5\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, loss_criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator,  loss_criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "  if  valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.657 | Train Acc: 60.41%\n",
            "\t Val. Loss: 0.569 |  Val. Acc: 71.56%\n",
            "Epoch: 02 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.558 | Train Acc: 71.62%\n",
            "\t Val. Loss: 0.405 |  Val. Acc: 82.65%\n",
            "Epoch: 03 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.435 | Train Acc: 80.56%\n",
            "\t Val. Loss: 0.390 |  Val. Acc: 83.33%\n",
            "Epoch: 04 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.345 | Train Acc: 85.38%\n",
            "\t Val. Loss: 0.399 |  Val. Acc: 84.20%\n",
            "Epoch: 05 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.302 | Train Acc: 87.67%\n",
            "\t Val. Loss: 0.284 |  Val. Acc: 88.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUweM0_2i6pp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fa98d602-dd11-423f-8608-53d117901932"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, valid_iterator, loss_criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.284 | Test Acc: 88.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9f3zgWLlESB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "  model.eval()\n",
        "  tokenized = tokenize(sentence)\n",
        "  indexed = [spacy_tokenizer.vocab.stoi[t] for t in tokenized]\n",
        "  length = [len(indexed)]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  length_tensor = torch.LongTensor(length)\n",
        "  prediction = torch.sigmoid(model.predict(tensor, length_tensor))\n",
        "  return prediction.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygu5ZDj59MAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "64b8df9d-75c8-4220-9199-7975ec185b50"
      },
      "source": [
        "#Negative Review\n",
        "predict_sentiment(model, \"This flim is terrible\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.007143225520849228"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYX3eDIMgAhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dc2b6de1-ce7a-4a32-bd1f-1c8297e20b15"
      },
      "source": [
        "#Positive Review\n",
        "predict_sentiment(model, \"This flim is great\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9603269696235657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    }
  ]
}