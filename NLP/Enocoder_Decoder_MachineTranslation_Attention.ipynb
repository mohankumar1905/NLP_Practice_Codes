{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Enocoder_Decoder_MachineTranslation_Attention.ipynb","version":"0.3.2","provenance":[{"file_id":"1JGg2_NQiTD0rluY1Xe-yq4ISAEri-CMX","timestamp":1558883261330}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PGYWRX67TfyT","colab_type":"code","outputId":"60150087-d50e-4281-cfda-79247008006f","executionInfo":{"status":"ok","timestamp":1558893145904,"user_tz":-330,"elapsed":26854,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N7vahz90TImD","colab_type":"code","outputId":"6c5c2d2d-aa6f-4218-8e52-5b5bb519457e","executionInfo":{"status":"ok","timestamp":1558897135745,"user_tz":-330,"elapsed":4352,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import numpy as np\n","import string\n","import re\n","from unicodedata import normalize\n","from matplotlib import pyplot as plt\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import Embedding\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"N00-Z3d1TyMZ","colab_type":"code","outputId":"230f3578-9b25-4dcc-a99d-e62078fd2bcc","executionInfo":{"status":"ok","timestamp":1558897138659,"user_tz":-330,"elapsed":1996,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["df = pd.read_csv(\"/content/drive/My Drive/Deep Learning/deueng/deu.txt\",encoding='utf-8', delimiter = r'\\t', header=None)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WoIKFt_aUY5E","colab_type":"code","colab":{}},"source":["df.columns = ['English', 'German']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyIfoVqaZlD-","colab_type":"code","colab":{}},"source":["df['German'] = df['German'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmPdieriaNE1","colab_type":"code","colab":{}},"source":["df['English']  = df['English'].str.replace(\"won't\",\"will not\")\n","df['English']  = df['English'].str.replace(\"ain't\",\"am not\")\n","df['English']  = df['English'].str.replace(\"'s\",\" is\")\n","df['English']  = df['English'].str.replace(\"'m\",\" am\")\n","df['English']  = df['English'].str.replace(\"'re'\",\" are\")\n","df['English']  = df['English'].str.replace(\"can't\",\"can not\")\n","df['English']  = df['English'].str.replace(\"'ll\",\" will\")\n","df['English']  = df['English'].str.replace(\"n't\",\" not\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLGm03TOeVn4","colab_type":"code","colab":{}},"source":["df['German'] = df['German'].str.replace(\"'s\",\" es\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFCgIZtrkjR5","colab_type":"code","colab":{}},"source":["df['English'] = df['English'].map(lambda x: x.lower())\n","df['German'] = df['German'].map(lambda x: x.lower())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qyXaunHhpAFz","colab_type":"code","colab":{}},"source":["df['English'] = df['English'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x)) #removing all charecters except alphabets\n","df['English'] = df['English'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces\n","df['English'] = df['English'].map(lambda x: ' '.join(word for word in x.split() if len(word)>1)) #removing single charecters'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lbc3L8kqp4xH","colab_type":"code","colab":{}},"source":["df['German'] = df['German'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x)) #removing all charecters except alphabets\n","df['German'] = df['German'].apply(lambda x: re.sub(r'\\s+',' ',x)) #removing extra spaces\n","df['German'] = df['German'].map(lambda x: ' '.join(word for word in x.split() if len(word)>1)) #removing single charecters'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rXoLcNqp8QP","colab_type":"code","outputId":"bb34582d-6dfe-434c-da43-b10d92b9fac4","executionInfo":{"status":"ok","timestamp":1558897147589,"user_tz":-330,"elapsed":1973,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df['English'][22519]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'call 110 right now'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"GEzAWJy8fkmt","colab_type":"code","outputId":"d7546fc3-a6c0-4453-a829-d7cfc32c320c","executionInfo":{"status":"ok","timestamp":1558897147590,"user_tz":-330,"elapsed":859,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(192881, 2)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"8uDLBcJjvwRa","colab_type":"code","colab":{}},"source":["df = df[0:10000]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAS7Z605wQl_","colab_type":"code","colab":{}},"source":["df_train = df[:9000]\n","df_test = df[9000:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMAkWobrrnQb","colab_type":"code","outputId":"e70fca71-543c-4fc8-f47f-2abe06aaecd6","executionInfo":{"status":"ok","timestamp":1558897150061,"user_tz":-330,"elapsed":751,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["english_tokenizer = Tokenizer()\n","english_tokenizer.fit_on_texts(df['English'])\n","eng_vocab_size = len(english_tokenizer.word_index)+1\n","print (eng_vocab_size)\n","print (max([len(x) for x in df['English'].str.split()]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2205\n","5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y8Zq1Axis3qx","colab_type":"code","colab":{}},"source":["eng_max_len = (max([len(x) for x in df['English'].str.split()]))\n","eng_max_len = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BuMjIzVPuKpJ","colab_type":"code","outputId":"5b5b1c9c-ad67-4087-cf51-91f27bbeeb48","executionInfo":{"status":"ok","timestamp":1558897152798,"user_tz":-330,"elapsed":1032,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["german_tokenizer = Tokenizer()\n","german_tokenizer.fit_on_texts(df['German'])\n","german_vocab_size = len(german_tokenizer.word_index)+1\n","print (german_vocab_size)\n","print (max([len(x) for x in df['German'].str.split()]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3565\n","10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hIvwvSE8s9EO","colab_type":"code","colab":{}},"source":["german_max_len = (max([len(x) for x in df['German'].str.split()]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iY-DM0wMgxBO","colab_type":"code","colab":{}},"source":["trainX = german_tokenizer.texts_to_sequences(df_train['German'])\n","trainX = pad_sequences(trainX, maxlen=german_max_len, padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yamkBJlZxGGx","colab_type":"code","outputId":"cfed09c7-7598-4546-901b-68866d54a7d9","executionInfo":{"status":"ok","timestamp":1558897156686,"user_tz":-330,"elapsed":569,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["trainX.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9000, 10)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"AksYjEzff2a5","colab_type":"code","colab":{}},"source":["trainY = english_tokenizer.texts_to_sequences(df_train['English'])\n","trainY = pad_sequences(trainY, maxlen=eng_max_len, padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePDA9c0EsGSM","colab_type":"code","outputId":"40a08de0-3c1f-4253-b8cf-d92b6c3d8dfb","executionInfo":{"status":"ok","timestamp":1558897159624,"user_tz":-330,"elapsed":617,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["trainY.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9000, 10)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"5_9gH8yAqwoh","colab_type":"code","colab":{}},"source":["trainY = to_categorical(trainY, num_classes=eng_vocab_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3D7EyUpIq5zC","colab_type":"code","outputId":"c68412e8-3a07-4915-bdc0-a4e562444fbf","executionInfo":{"status":"ok","timestamp":1558897167507,"user_tz":-330,"elapsed":900,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["trainY.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9000, 10, 2205)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"euJEaMGmxCPG","colab_type":"code","outputId":"54efcc99-4168-4a77-fbbc-cf41784b6679","executionInfo":{"status":"ok","timestamp":1558897175308,"user_tz":-330,"elapsed":904,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["testX = german_tokenizer.texts_to_sequences(df_test['German'])\n","testX = pad_sequences(testX, maxlen=german_max_len, padding='post')\n","testY = english_tokenizer.texts_to_sequences(df_test['English'])\n","testY = pad_sequences(testY, maxlen=eng_max_len, padding='post')\n","testY = to_categorical(testY, num_classes=eng_vocab_size)\n","testY.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 10, 2205)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"qSCgDTdnvTsE","colab_type":"code","colab":{}},"source":["embedding_size = 256"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uy4FnvphT43E","colab_type":"code","colab":{}},"source":["def time_distributed_dense(x, w, b=None, dropout=None,\n","                           input_dim=None, output_dim=None, timesteps=None):\n","    '''Apply y.w + b for every temporal slice y of x.\n","    '''\n","    if not input_dim:\n","        # won't work with TensorFlow\n","        input_dim = K.shape(x)[2]\n","    if not timesteps:\n","        # won't work with TensorFlow\n","        timesteps = K.shape(x)[1]\n","    if not output_dim:\n","        # won't work with TensorFlow\n","        output_dim = K.shape(w)[1]\n","\n","    if dropout:\n","        # apply the same dropout pattern at every timestep\n","        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n","        dropout_matrix = K.dropout(ones, dropout)\n","        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n","        x *= expanded_dropout_matrix\n","\n","    # collapse time dimension and batch dimension together\n","    x = K.reshape(x, (-1, input_dim))\n","\n","    x = K.dot(x, w)\n","    if b:\n","        x = x + b\n","    # reshape to 3D tensor\n","    x = K.reshape(x, (-1, timesteps, output_dim))\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipjvViXiryMJ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from keras import backend as K\n","from keras import regularizers, constraints, initializers, activations\n","from keras.layers.recurrent import Recurrent\n","from keras.layers import TimeDistributed, Dense\n","from keras.engine import InputSpec\n","\n","tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n","\n","class AttentionDecoder(Recurrent):\n","\n","    def __init__(self, units, output_dim,\n","                 activation='tanh',\n","                 return_probabilities=False,\n","                 name='AttentionDecoder',\n","                 kernel_initializer='glorot_uniform',\n","                 recurrent_initializer='orthogonal',\n","                 bias_initializer='zeros',\n","                 kernel_regularizer=None,\n","                 bias_regularizer=None,\n","                 activity_regularizer=None,\n","                 kernel_constraint=None,\n","                 bias_constraint=None,\n","                 **kwargs):\n","        \"\"\"\n","        Implements an AttentionDecoder that takes in a sequence encoded by an\n","        encoder and outputs the decoded states\n","        :param units: dimension of the hidden state and the attention matrices\n","        :param output_dim: the number of labels in the output space\n","\n","        references:\n","            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n","            \"Neural machine translation by jointly learning to align and translate.\"\n","            arXiv preprint arXiv:1409.0473 (2014).\n","        \"\"\"\n","        self.units = units\n","        self.output_dim = output_dim\n","        self.return_probabilities = return_probabilities\n","        self.activation = activations.get(activation)\n","        self.kernel_initializer = initializers.get(kernel_initializer)\n","        self.recurrent_initializer = initializers.get(recurrent_initializer)\n","        self.bias_initializer = initializers.get(bias_initializer)\n","\n","        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n","        self.bias_regularizer = regularizers.get(bias_regularizer)\n","        self.activity_regularizer = regularizers.get(activity_regularizer)\n","\n","        self.kernel_constraint = constraints.get(kernel_constraint)\n","        self.recurrent_constraint = constraints.get(kernel_constraint)\n","        self.bias_constraint = constraints.get(bias_constraint)\n","\n","        super(AttentionDecoder, self).__init__(**kwargs)\n","        self.name = name\n","        self.return_sequences = True  # must return sequences\n","\n","    def build(self, input_shape):\n","        \"\"\"\n","          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n","          for model details that correspond to the matrices here.\n","        \"\"\"\n","\n","        self.batch_size, self.timesteps, self.input_dim = input_shape\n","\n","        if self.stateful:\n","            super(AttentionDecoder, self).reset_states()\n","\n","        self.states = [None, None]  # y, s\n","\n","        \"\"\"\n","            Matrices for creating the context vector\n","        \"\"\"\n","\n","        self.V_a = self.add_weight(shape=(self.units,),\n","                                   name='V_a',\n","                                   initializer=self.kernel_initializer,\n","                                   regularizer=self.kernel_regularizer,\n","                                   constraint=self.kernel_constraint)\n","        self.W_a = self.add_weight(shape=(self.units, self.units),\n","                                   name='W_a',\n","                                   initializer=self.kernel_initializer,\n","                                   regularizer=self.kernel_regularizer,\n","                                   constraint=self.kernel_constraint)\n","        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='U_a',\n","                                   initializer=self.kernel_initializer,\n","                                   regularizer=self.kernel_regularizer,\n","                                   constraint=self.kernel_constraint)\n","        self.b_a = self.add_weight(shape=(self.units,),\n","                                   name='b_a',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","        \"\"\"\n","            Matrices for the r (reset) gate\n","        \"\"\"\n","        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='C_r',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_r = self.add_weight(shape=(self.units, self.units),\n","                                   name='U_r',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n","                                   name='W_r',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_r = self.add_weight(shape=(self.units, ),\n","                                   name='b_r',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","\n","        \"\"\"\n","            Matrices for the z (update) gate\n","        \"\"\"\n","        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='C_z',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_z = self.add_weight(shape=(self.units, self.units),\n","                                   name='U_z',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n","                                   name='W_z',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_z = self.add_weight(shape=(self.units, ),\n","                                   name='b_z',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","        \"\"\"\n","            Matrices for the proposal\n","        \"\"\"\n","        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='C_p',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_p = self.add_weight(shape=(self.units, self.units),\n","                                   name='U_p',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n","                                   name='W_p',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_p = self.add_weight(shape=(self.units, ),\n","                                   name='b_p',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","        \"\"\"\n","            Matrices for making the final prediction vector\n","        \"\"\"\n","        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n","                                   name='C_o',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n","                                   name='U_o',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n","                                   name='W_o',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_o = self.add_weight(shape=(self.output_dim, ),\n","                                   name='b_o',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","\n","        # For creating the initial state:\n","        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='W_s',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","\n","        self.input_spec = [\n","            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n","        self.built = True\n","\n","    def call(self, x):\n","        # store the whole sequence so we can \"attend\" to it at each timestep\n","        self.x_seq = x\n","\n","        # apply the a dense layer over the time dimension of the sequence\n","        # do it here because it doesn't depend on any previous steps\n","        # thefore we can save computation time:\n","        self._uxpb = time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n","                                             input_dim=self.input_dim,\n","                                             timesteps=self.timesteps,\n","                                             output_dim=self.units)\n","\n","        return super(AttentionDecoder, self).call(x)\n","\n","    def get_initial_state(self, inputs):\n","        # apply the matrix on the first time step to get the initial s0.\n","        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n","\n","        # from keras.layers.recurrent to initialize a vector of (batchsize,\n","        # output_dim)\n","        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n","        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n","        y0 = K.expand_dims(y0)  # (samples, 1)\n","        y0 = K.tile(y0, [1, self.output_dim])\n","\n","        return [y0, s0]\n","\n","    def step(self, x, states):\n","\n","        ytm, stm = states\n","\n","        # repeat the hidden state to the length of the sequence\n","        _stm = K.repeat(stm, self.timesteps)\n","\n","        # now multiplty the weight matrix with the repeated hidden state\n","        _Wxstm = K.dot(_stm, self.W_a)\n","\n","        # calculate the attention probabilities\n","        # this relates how much other timesteps contributed to this one.\n","        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n","                   K.expand_dims(self.V_a))\n","        at = K.exp(et)\n","        at_sum = K.sum(at, axis=1)\n","        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n","        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n","\n","        # calculate the context vector\n","        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n","        # ~~~> calculate new hidden state\n","        # first calculate the \"r\" gate:\n","\n","        rt = activations.sigmoid(\n","            K.dot(ytm, self.W_r)\n","            + K.dot(stm, self.U_r)\n","            + K.dot(context, self.C_r)\n","            + self.b_r)\n","\n","        # now calculate the \"z\" gate\n","        zt = activations.sigmoid(\n","            K.dot(ytm, self.W_z)\n","            + K.dot(stm, self.U_z)\n","            + K.dot(context, self.C_z)\n","            + self.b_z)\n","\n","        # calculate the proposal hidden state:\n","        s_tp = activations.tanh(\n","            K.dot(ytm, self.W_p)\n","            + K.dot((rt * stm), self.U_p)\n","            + K.dot(context, self.C_p)\n","            + self.b_p)\n","\n","        # new hidden state:\n","        st = (1-zt)*stm + zt * s_tp\n","\n","        yt = activations.softmax(\n","            K.dot(ytm, self.W_o)\n","            + K.dot(stm, self.U_o)\n","            + K.dot(context, self.C_o)\n","            + self.b_o)\n","\n","        if self.return_probabilities:\n","            return at, [yt, st]\n","        else:\n","            return yt, [yt, st]\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\"\n","            For Keras internal compatability checking\n","        \"\"\"\n","        if self.return_probabilities:\n","            return (None, self.timesteps, self.timesteps)\n","        else:\n","            return (None, self.timesteps, self.output_dim)\n","\n","    def get_config(self):\n","        \"\"\"\n","            For rebuilding models on load time.\n","        \"\"\"\n","        config = {\n","            'output_dim': self.output_dim,\n","            'units': self.units,\n","            'return_probabilities': self.return_probabilities\n","        }\n","        base_config = super(AttentionDecoder, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnJpRSccr7GM","colab_type":"code","outputId":"888b3392-610b-44c6-d9a0-4f2682acb909","executionInfo":{"status":"ok","timestamp":1558897192132,"user_tz":-330,"elapsed":8480,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":314}},"source":["model = Sequential()\n","model.add(Embedding(german_vocab_size,embedding_size,input_length=german_max_len))\n","model.add(LSTM(100,return_sequences=True))\n","model.add(AttentionDecoder(100, eng_vocab_size))\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 10, 256)           912640    \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 10, 100)           142800    \n","_________________________________________________________________\n","AttentionDecoder (AttentionD (None, 10, 2205)          6057230   \n","=================================================================\n","Total params: 7,112,670\n","Trainable params: 7,112,670\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o3TIlyF8watj","colab_type":"code","colab":{}},"source":["# fit model\n","filename = 'model.h5'\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVKS5Dc0xuFE","colab_type":"code","outputId":"dd99872a-efe6-4440-b52a-acc09c60edfa","executionInfo":{"status":"ok","timestamp":1558897330091,"user_tz":-330,"elapsed":134688,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":2197}},"source":["model.fit(trainX, trainY, epochs=30, batch_size=128, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 9000 samples, validate on 1000 samples\n","Epoch 1/30\n"," - 8s - loss: 3.2227 - val_loss: 2.1422\n","\n","Epoch 00001: val_loss improved from inf to 2.14217, saving model to model.h5\n","Epoch 2/30\n"," - 4s - loss: 1.6074 - val_loss: 2.0690\n","\n","Epoch 00002: val_loss improved from 2.14217 to 2.06901, saving model to model.h5\n","Epoch 3/30\n"," - 4s - loss: 1.5311 - val_loss: 2.0278\n","\n","Epoch 00003: val_loss improved from 2.06901 to 2.02778, saving model to model.h5\n","Epoch 4/30\n"," - 4s - loss: 1.4613 - val_loss: 1.9931\n","\n","Epoch 00004: val_loss improved from 2.02778 to 1.99307, saving model to model.h5\n","Epoch 5/30\n"," - 4s - loss: 1.3988 - val_loss: 1.9761\n","\n","Epoch 00005: val_loss improved from 1.99307 to 1.97611, saving model to model.h5\n","Epoch 6/30\n"," - 4s - loss: 1.3522 - val_loss: 1.9300\n","\n","Epoch 00006: val_loss improved from 1.97611 to 1.92999, saving model to model.h5\n","Epoch 7/30\n"," - 4s - loss: 1.3067 - val_loss: 1.9021\n","\n","Epoch 00007: val_loss improved from 1.92999 to 1.90211, saving model to model.h5\n","Epoch 8/30\n"," - 4s - loss: 1.2573 - val_loss: 1.8583\n","\n","Epoch 00008: val_loss improved from 1.90211 to 1.85826, saving model to model.h5\n","Epoch 9/30\n"," - 4s - loss: 1.2044 - val_loss: 1.8362\n","\n","Epoch 00009: val_loss improved from 1.85826 to 1.83622, saving model to model.h5\n","Epoch 10/30\n"," - 4s - loss: 1.1532 - val_loss: 1.8146\n","\n","Epoch 00010: val_loss improved from 1.83622 to 1.81457, saving model to model.h5\n","Epoch 11/30\n"," - 4s - loss: 1.1083 - val_loss: 1.8060\n","\n","Epoch 00011: val_loss improved from 1.81457 to 1.80604, saving model to model.h5\n","Epoch 12/30\n"," - 4s - loss: 1.0689 - val_loss: 1.7816\n","\n","Epoch 00012: val_loss improved from 1.80604 to 1.78158, saving model to model.h5\n","Epoch 13/30\n"," - 4s - loss: 1.0301 - val_loss: 1.7444\n","\n","Epoch 00013: val_loss improved from 1.78158 to 1.74440, saving model to model.h5\n","Epoch 14/30\n"," - 4s - loss: 0.9901 - val_loss: 1.7208\n","\n","Epoch 00014: val_loss improved from 1.74440 to 1.72076, saving model to model.h5\n","Epoch 15/30\n"," - 4s - loss: 0.9455 - val_loss: 1.7067\n","\n","Epoch 00015: val_loss improved from 1.72076 to 1.70671, saving model to model.h5\n","Epoch 16/30\n"," - 4s - loss: 0.9045 - val_loss: 1.7034\n","\n","Epoch 00016: val_loss improved from 1.70671 to 1.70335, saving model to model.h5\n","Epoch 17/30\n"," - 4s - loss: 0.8606 - val_loss: 1.6612\n","\n","Epoch 00017: val_loss improved from 1.70335 to 1.66115, saving model to model.h5\n","Epoch 18/30\n"," - 4s - loss: 0.8193 - val_loss: 1.6742\n","\n","Epoch 00018: val_loss did not improve from 1.66115\n","Epoch 19/30\n"," - 4s - loss: 0.7789 - val_loss: 1.6819\n","\n","Epoch 00019: val_loss did not improve from 1.66115\n","Epoch 20/30\n"," - 4s - loss: 0.7405 - val_loss: 1.6468\n","\n","Epoch 00020: val_loss improved from 1.66115 to 1.64678, saving model to model.h5\n","Epoch 21/30\n"," - 4s - loss: 0.7024 - val_loss: 1.6424\n","\n","Epoch 00021: val_loss improved from 1.64678 to 1.64244, saving model to model.h5\n","Epoch 22/30\n"," - 4s - loss: 0.6617 - val_loss: 1.6214\n","\n","Epoch 00022: val_loss improved from 1.64244 to 1.62140, saving model to model.h5\n","Epoch 23/30\n"," - 4s - loss: 0.6241 - val_loss: 1.6258\n","\n","Epoch 00023: val_loss did not improve from 1.62140\n","Epoch 24/30\n"," - 4s - loss: 0.5877 - val_loss: 1.6195\n","\n","Epoch 00024: val_loss improved from 1.62140 to 1.61954, saving model to model.h5\n","Epoch 25/30\n"," - 4s - loss: 0.5509 - val_loss: 1.5951\n","\n","Epoch 00025: val_loss improved from 1.61954 to 1.59506, saving model to model.h5\n","Epoch 26/30\n"," - 4s - loss: 0.5170 - val_loss: 1.6019\n","\n","Epoch 00026: val_loss did not improve from 1.59506\n","Epoch 27/30\n"," - 4s - loss: 0.4846 - val_loss: 1.6310\n","\n","Epoch 00027: val_loss did not improve from 1.59506\n","Epoch 28/30\n"," - 4s - loss: 0.4508 - val_loss: 1.6209\n","\n","Epoch 00028: val_loss did not improve from 1.59506\n","Epoch 29/30\n"," - 4s - loss: 0.4201 - val_loss: 1.5976\n","\n","Epoch 00029: val_loss did not improve from 1.59506\n","Epoch 30/30\n"," - 4s - loss: 0.3909 - val_loss: 1.5934\n","\n","Epoch 00030: val_loss improved from 1.59506 to 1.59339, saving model to model.h5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe17dce1780>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"u8hnobbgxwt-","colab_type":"code","outputId":"736afeb0-fde5-4f74-ecd2-342a249d10f1","executionInfo":{"status":"ok","timestamp":1558897334234,"user_tz":-330,"elapsed":868,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["englishword_for_id = dict((v,k) for k,v in english_tokenizer.word_index.items())  \n","englishword_for_id[1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'tom'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"2Ynq0Lhkb3Or","colab_type":"code","outputId":"0a19e014-c348-4a5a-cc09-fe31fbf8167a","executionInfo":{"status":"ok","timestamp":1558897637760,"user_tz":-330,"elapsed":894,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["for word in np.argmax(model.predict(pad_sequences(german_tokenizer.texts_to_sequences([\"ich habe gestern einen Film gesehen\"]),padding=\"post\",maxlen=10)),axis=2)[0]:\n","  if word != 0:\n","    print (englishword_for_id[word])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["saw\n","that\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_riH_eivccHh","colab_type":"code","outputId":"060a5183-2d2c-4fe9-a1fe-f99ef5dce503","executionInfo":{"status":"ok","timestamp":1558246961980,"user_tz":-330,"elapsed":829,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["pad_sequences(german_tokenizer.texts_to_sequences([\"Guten Morgen Jagan\"]),padding=\"post\",maxlen=10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1165,  424,    0,    0,    0,    0,    0,    0,    0,    0]],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"BH63xfkIcpjI","colab_type":"code","outputId":"9031484e-c254-425e-912f-b1ab7cc41b3c","executionInfo":{"status":"ok","timestamp":1558897674670,"user_tz":-330,"elapsed":913,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["predict_sentence_split = []\n","for word in np.argmax(model.predict(pad_sequences(german_tokenizer.texts_to_sequences([df['German'][9999]]),padding=\"post\",maxlen=10)),axis=2)[0]:\n","  if word != 0:\n","    print (englishword_for_id[word])\n","    predict_sentence_split.append(englishword_for_id[word])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["found\n","it\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"axMPr2VAegeU","colab_type":"code","colab":{}},"source":["from nltk.translate.bleu_score import sentence_bleu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9v6GPm9plQA","colab_type":"code","outputId":"a4c3984d-ed33-4b8e-c3eb-34e3a7bfcb54","executionInfo":{"status":"ok","timestamp":1558897686295,"user_tz":-330,"elapsed":854,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df['English'][9999]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'just found it'"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"u56OfuqaxjEw","colab_type":"code","outputId":"7601eda2-5bad-43ed-adb2-32d36d33fbc6","executionInfo":{"status":"ok","timestamp":1558897690308,"user_tz":-330,"elapsed":1100,"user":{"displayName":"Mohankumar Balasubramaniyam","photoUrl":"https://lh4.googleusercontent.com/-WDGyxwVw0Dw/AAAAAAAAAAI/AAAAAAAAMXg/s0XKgKv-dN8/s64/photo.jpg","userId":"03872728872081242131"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["sentence_bleu([df['English'][9999].split()],predict_sentence_split)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.6065306597126334"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"PdDjH7w-yXJH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}