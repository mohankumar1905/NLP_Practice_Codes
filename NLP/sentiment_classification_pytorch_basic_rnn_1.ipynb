{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_classification_pytorch_basic_rnn_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARTq2oijAtIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "03c862b4-a462-4156-8628-3cf660bdaca7"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusdsAIJAugX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path =  \"/content/drive/My Drive/Movie_Reviews/csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugxCqyypA8Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchtext\n",
        "import spacy\n",
        "import time\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset, LabelField"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqiZ3BgF7oY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "493d0751-103e-445a-83df-060bdcb4e5bc"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLeuelX3_myt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P6zW_zuK67T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cfda5af4-c95f-4a93-f6ad-186dd6b713ca"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIkWSqXlBWH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(f\"{path}/train.csv\")\n",
        "test_df = pd.read_csv(f\"{path}/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIGOYqfiBb6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d8b16504-fdf5-46a9-b958-6079d7fba7a1"
      },
      "source": [
        "print(f'Number of training examples: {len(train_df)}')\n",
        "print(f'Number of testing examples: {len(test_df)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF8hstRbC-lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6677bcf7-d068-4c14-c902-f1f96d823f20"
      },
      "source": [
        "train_split, val_split = train_test_split(train_df, test_size=0.3, random_state=1994)\n",
        "train_split.shape, val_split.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 2), (7500, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVz0iAzEfR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split.to_csv(f\"{path}/train_split.csv\", index=False)\n",
        "val_split.to_csv(f\"{path}/val_split.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Vkc00sNP5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = spacy.load('en')\n",
        "def tokenize(sentence):\n",
        "  return [tok.text for tok in en.tokenizer(sentence)]\n",
        "spacy_tokenizer = Field(tokenize=tokenize)\n",
        "LABEL = LabelField(dtype = torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw0bSOy3NQAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "72056ead-dd97-4bb4-ee1b-725a0f6309c1"
      },
      "source": [
        "tokenize(\"i don't love you\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'do', \"n't\", 'love', 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TazS1OXxNQKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# associate the text in the 'English' column with the EN_TEXT field, #\n",
        "data_fields = [('reviews', spacy_tokenizer), ('pos_or_neg', LABEL)]\n",
        "train, val, test = TabularDataset.splits(path=path, train='train_split.csv', validation='val_split.csv',\n",
        "                                         test='test.csv', format='csv', skip_header=True, fields=data_fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zePvw1A7NQQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "eb8f6f7c-e21d-44d7-f0f8-ef98a39a59cb"
      },
      "source": [
        "print(f'Number of training examples: {len(train)}')\n",
        "print(f'Number of testing examples: {len(val)}')\n",
        "print(f'Number of training examples: {len(test)}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of testing examples: 7500\n",
            "Number of training examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-ChmQLBNQIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "5378ec86-dab3-4893-9732-ba8bb31cd0d9"
      },
      "source": [
        "print(vars(train.examples[0])), print(vars(val.examples[0])), print(vars(test.examples[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'reviews': ['When', 'will', 'the', 'hurting', 'stop', '?', 'I', 'never', 'want', 'to', 'see', 'another', 'version', 'of', 'a', 'Christmas', 'Carol', 'again', '.', 'They', 'keep', 'on', 'making', 'movies', 'with', 'the', 'same', 'story', ',', 'falling', 'over', 'each', 'other', 'in', 'trying', 'to', 'make', 'the', 'movie', 'better', 'then', 'the', 'rest', ',', 'but', 'sadly', 'fail', 'to', 'do', 'so', ',', 'as', 'this', 'is', 'not', 'a', 'good', 'story', '.', 'Moralistic', ',', 'old', '-', 'fashioned', ',', 'conservative', 'happy', '-', 'thinking', '.', 'As', 'if', 'people', 'learn', '.', 'The', 'numerous', 'different', 'versions', 'of', 'this', 'film', 'prove', 'that', 'we', 'donÂ´t', '.'], 'pos_or_neg': '0'}\n",
            "{'reviews': ['Kol', ',', 'space', 'prisoner', 'on', 'space', 'death', 'row', ',', 'manages', 'to', 'hijack', 'a', 'space', 'shuttle', 'and', 'escape', 'to', 'the', 'woods', 'of', 'America', 'where', 'he', ',', 'along', 'with', 'some', 'new', 'found', 'friend', 'try', 'to', 'escape', 'from', 'the', \"'\", 'Alienator', '\"', 'a', 'female', 'cyborg', 'killing', 'machine', '.', 'Made', 'one', 'year', 'after', 'the', 'best', 'movie', 'of', 'Fred', 'Olen', 'Ray', \"'s\", 'career', ',', '\"', 'Hollywood', 'Chainsaw', 'Hookers', '\"', ',', 'this', 'one', 'ca', \"n't\", 'help', 'but', 'feel', 'like', 'a', 'bit', 'of', 'a', 'letdown', '.', 'Just', 'as', 'low', '-', 'budget', 'as', 'that', 'earlier', 'film', ',', 'but', 'not', 'nearly', 'as', 'fun', 'as', 'I', 'had', 'with', 'it', '.', 'None', 'of', 'the', 'actors', 'really', 'stood', 'out', 'at', 'me', '.', 'The', 'film', 'is', 'alright', 'for', 'the', 'undiscriminating', 'viewer', 'during', 'a', 'rainy', 'Saturday', 'afternoon', ',', 'but', 'that', \"'s\", 'pretty', 'much', 'all', 'it', \"'s\", 'good', 'for.<br', '/><br', '/>My', 'Grade', ':', 'D+', '<', 'br', '/><br', '/>Where', 'i', 'saw', 'it', ':', 'Showtime', 'Thriller'], 'pos_or_neg': '0'}\n",
            "{'reviews': ['I', 'went', 'and', 'saw', 'this', 'movie', 'last', 'night', 'after', 'being', 'coaxed', 'to', 'by', 'a', 'few', 'friends', 'of', 'mine', '.', 'I', \"'ll\", 'admit', 'that', 'I', 'was', 'reluctant', 'to', 'see', 'it', 'because', 'from', 'what', 'I', 'knew', 'of', 'Ashton', 'Kutcher', 'he', 'was', 'only', 'able', 'to', 'do', 'comedy', '.', 'I', 'was', 'wrong', '.', 'Kutcher', 'played', 'the', 'character', 'of', 'Jake', 'Fischer', 'very', 'well', ',', 'and', 'Kevin', 'Costner', 'played', 'Ben', 'Randall', 'with', 'such', 'professionalism', '.', 'The', 'sign', 'of', 'a', 'good', 'movie', 'is', 'that', 'it', 'can', 'toy', 'with', 'our', 'emotions', '.', 'This', 'one', 'did', 'exactly', 'that', '.', 'The', 'entire', 'theater', '(', 'which', 'was', 'sold', 'out', ')', 'was', 'overcome', 'by', 'laughter', 'during', 'the', 'first', 'half', 'of', 'the', 'movie', ',', 'and', 'were', 'moved', 'to', 'tears', 'during', 'the', 'second', 'half', '.', 'While', 'exiting', 'the', 'theater', 'I', 'not', 'only', 'saw', 'many', 'women', 'in', 'tears', ',', 'but', 'many', 'full', 'grown', 'men', 'as', 'well', ',', 'trying', 'desperately', 'not', 'to', 'let', 'anyone', 'see', 'them', 'crying', '.', 'This', 'movie', 'was', 'great', ',', 'and', 'I', 'suggest', 'that', 'you', 'go', 'see', 'it', 'before', 'you', 'judge', '.'], 'pos_or_neg': '1'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yxYDC8qZM5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv-PKlmXaAM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "82217af7-038d-491b-8592-5f7c8482e05a"
      },
      "source": [
        "spacy_tokenizer.build_vocab(train, max_size=MAX_VOCAB_SIZE, include_lengths=True)\n",
        "LABEL.build_vocab(train)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(spacy_tokenizer.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqjhyFA7adPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fef3b8e3-8b0d-4874-f47a-5d36e708fcfb"
      },
      "source": [
        "print(spacy_tokenizer.vocab.freqs.most_common(20))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 202228), (',', 191811), ('.', 166104), ('a', 109545), ('and', 109108), ('of', 100261), ('to', 93586), ('is', 76219), ('in', 61112), ('I', 53952), ('it', 53535), ('that', 49080), ('\"', 44472), (\"'s\", 43144), ('this', 42114), ('-', 36966), ('/><br', 35439), ('was', 34960), ('as', 30261), ('with', 30017)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9EQPJQIaAJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "80765b12-8f78-42ad-8230-44b243b9f6d3"
      },
      "source": [
        "print(spacy_tokenizer.vocab.itos[:10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1JnVMosaAGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1c5ddf94-e20a-4002-ca19-8fe8e8c33459"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f79236e2840>, {'0': 0, '1': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v44ABIrbiik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, val, test), batch_size = BATCH_SIZE, device=device, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUkLZRZPFbzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "  def forward(self, text):\n",
        "    #text should be in the shape of Sentence Size, batch_length\n",
        "    embedded = self.embedding(text)\n",
        "    #embedding outputs  sentence size, batch length , embedding vector_dimensions\n",
        "    output, hidden = self.rnn(embedded)\n",
        "    #output is the concatenation of the hidden state from every time step(sent_len, batch_size, hidden_length), whereas hidden(1, batch_size, hidden_length)\n",
        "    #is simply the final hidden state. We verify this using the assert statement. Note the squeeze method, which is used to remove a dimension of size 1.\n",
        "    squeezed_hidden = hidden.squeeze(0)\n",
        "    assert torch.equal(output[-1,:,:], squeezed_hidden)\n",
        "    x = self.fc(squeezed_hidden)\n",
        "    return x\n",
        "\n",
        "  def predict(self, text):\n",
        "    return self(text).squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBcAlDMWIZfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 25002\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S9Nz6z4I5Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e5e7b998-4a51-415f-df20-f932ea47d018"
      },
      "source": [
        "def count_trainable_parameters(model):\n",
        "  return sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "print(f\"The model has {count_trainable_parameters(model)} trainable parameters\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2592105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c56_ZoP-JzGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=10e-3)\n",
        "loss_criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g4T5OjDKnwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "loss_criterion = loss_criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBczBTZ7NL_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, target):\n",
        "  \"\"\"Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\"\"\"\n",
        "  #rounds prediction to the closest integer.\n",
        "  rounded_prediction = torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_prediction == target).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj2km9J7gMRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model.predict(batch.reviews) #.squeeze(1)\n",
        "    loss = criterion(predictions, batch.pos_or_neg)\n",
        "    acc = binary_accuracy(predictions, batch.pos_or_neg)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JZoes6lgplO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  #with torch.no_grad():\n",
        "  for batch in iterator:\n",
        "    predictions = model.predict(batch.reviews)#.squeeze(1)\n",
        "    loss = criterion(predictions, batch.pos_or_neg)\n",
        "    acc = binary_accuracy(predictions, batch.pos_or_neg)\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vuKWEdFkaTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yveNMZJRg1XZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "f0800ef8-54f7-4ae1-f87c-da0c073ee601"
      },
      "source": [
        "num_epochs = 5\n",
        "best_valid_loss = float('-inf')\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, loss_criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator,  loss_criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "  if  best_valid_loss < valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.35%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 49.61%\n",
            "Epoch: 02 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.47%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.46%\n",
            "Epoch: 03 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.62%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.46%\n",
            "Epoch: 04 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.10%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.46%\n",
            "Epoch: 05 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.97%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 49.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUweM0_2i6pp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "561294f2-f9c9-4b33-b481-a06165a90551"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, loss_criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.693 | Test Acc: 50.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9f3zgWLlESB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e41989f4-4b45-4704-c920-da109338e122"
      },
      "source": [
        "ls"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygu5ZDj59MAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}